{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5488135 ,  0.71518937,  0.60276338,  0.54488318,  0.4236548 ,\n",
       "         0.64589411,  0.43758721,  0.891773  ,  0.96366276,  0.38344152,\n",
       "        18.40631483],\n",
       "       [ 0.79172504,  0.52889492,  0.56804456,  0.92559664,  0.07103606,\n",
       "         0.0871293 ,  0.0202184 ,  0.83261985,  0.77815675,  0.87001215,\n",
       "        19.60677754]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "X, y = make_friedman1(n_samples=1200, random_state=0, noise=1.0)\n",
    "x_train, x_test = X[:200], X[200:300]\n",
    "y_train, y_test = y[:200], y[200:300]\n",
    "\n",
    "y_train = y_train.reshape((200, 1))\n",
    "data = np.concatenate([x_train, y_train], axis=1)\n",
    "\n",
    "y_test = y_test.reshape((x_test.shape[0], 1))\n",
    "testdata = np.concatenate([x_test, y_test], axis=1)\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class treeNode:\n",
    "    def __init__(self, label_class=None, feature=None, value=None, right_tree=None, left_tree=None):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.right_tree = right_tree\n",
    "        self.left_tree = left_tree\n",
    "        self.label_class = label_class\n",
    "        \n",
    "    def __name__(self):\n",
    "        return \"treenode\"\n",
    "    \n",
    "    \n",
    "class Tree:\n",
    "    def __init__(self, min_leafs=5, max_depth=10):\n",
    "        self.min_leafs = min_leafs\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def binsplitdata(self, data, feature, value):\n",
    "        mat0 = data[data[:, feature] > value, : ]\n",
    "        mat1 = data[data[:, feature] <= value, : ]\n",
    "        return mat0, mat1\n",
    "    \n",
    "    # 利用字典的方式创建一棵树。\n",
    "    \"\"\"\n",
    "    def createTree_old(self, data, leafType=regleaf, errType=regerr, ops=(1,4)):\n",
    "        # 这里阐释了如何 利用递归的思想去 建立决策树\n",
    "        feat, val = self.choosebestsplit(data, leafType, errType, ops)\n",
    "        # 如果没有可以再次切分的  feature 就返回val\n",
    "        if feat == None:\n",
    "            return val\n",
    "        # 这里注意创建了一个新的 字典？\n",
    "        retTree = {}\n",
    "        retTree['spInd'] = feat\n",
    "        retTree['spVal'] = val\n",
    "        lSet,rSet = self.binsplitdata(data,feat,val)\n",
    "        retTree['left'] = self.createTree_old(lSet,leafType,errType, ops)\n",
    "        retTree['right'] = self.createTree_old(rSet,leafType,errType, ops)\n",
    "        return retTree\n",
    "    \"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def get_deep(cls, model):\n",
    "        max_deep = 0\n",
    "        if model.right_tree is not None:\n",
    "            temp_deep = 1 + cls.get_deep(model.right_tree)\n",
    "            if temp_deep > max_deep:\n",
    "                max_deep = temp_deep\n",
    "        if model.left_tree is not None:\n",
    "            temp_deep = 1 + cls.get_deep(model.left_tree)\n",
    "            if temp_deep > max_deep:\n",
    "                max_deep = temp_deep\n",
    "        return max_deep\n",
    "\n",
    "    @classmethod\n",
    "    def print_leafs(cls, model):\n",
    "        if model.left_tree is not None:\n",
    "            cls.print_leafs(model.left_tree)\n",
    "        if model.label_class is not None:\n",
    "            print(\"leaf value is {}\".format(model.label_class))\n",
    "        if model.right_tree is not None:\n",
    "            cls.print_leafs(model.right_tree)\n",
    "            \n",
    "    @classmethod\n",
    "    def predict_line(cls, model, line):\n",
    "        if model.label_class is not None:\n",
    "            return model.label_class\n",
    "        split_feature = model.feature\n",
    "        split_value = model.value\n",
    "        if line[split_feature] > split_value:\n",
    "            return cls.predict_line(model.right_tree, line)\n",
    "        else:\n",
    "            return cls.predict_line(model.left_tree, line)\n",
    "        \n",
    "    @classmethod\n",
    "    def predict(cls, model, data):\n",
    "        myre = []\n",
    "        for line in data:\n",
    "            te = cls.predict_line(model, line)\n",
    "            myre.append(te)\n",
    "        myre = np.array(myre).reshape(len(data), 1)\n",
    "        return myre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cartreeregression(Tree):\n",
    "    def __init__(self, min_leafs=4):\n",
    "        super(cartreeregression, self).__init__()\n",
    "        self.min_leafs = min_leafs\n",
    "        \n",
    "    def regleaf(self, data):\n",
    "        return np.mean(data[:,-1])\n",
    "    \n",
    "    def regerr(self, data):\n",
    "        return np.var(data[:, -1]) \n",
    "    \n",
    "    def createTree(self, data):\n",
    "        retTree = treeNode()\n",
    "        # 可以添加其他条件,终止树 停止生长，分类和回归树有不同的搞法。\n",
    "        # 这里阐释了如何 利用递归的思想去 建立决策树\n",
    "        feat, val = self.choosebestsplit(data)\n",
    "        # 如果没有可以再次切分的  feature 就返回val\n",
    "        if feat is None:\n",
    "            retTree.label_class = self.regleaf(data)\n",
    "            return retTree\n",
    "        \n",
    "        retTree.feature = feat\n",
    "        retTree.value = val\n",
    "        lSet, rSet = self.binsplitdata(data, feat, val)\n",
    "        retTree.left_tree = self.createTree(lSet)\n",
    "        retTree.right_tree = self.createTree(rSet)\n",
    "        return retTree\n",
    "    \n",
    "    def choosebestsplit(self, data):\n",
    "        data = np.array(data)\n",
    "        m, n = data.shape\n",
    "    \n",
    "        # 计算初始的方差。\n",
    "        S = self.regerr(data)\n",
    "        best_s = np.inf\n",
    "        best_feat = None \n",
    "        best_val = None\n",
    "    \n",
    "        for i in range(n-1): # n-1 feature\n",
    "            for j in np.unique(data[:, i]):\n",
    "                mat0, mat1 = self.binsplitdata(data, i, j)\n",
    "                # 控制叶子的数量。不进行控制 进行充分的生长\n",
    "                if (np.shape(mat0)[0] < self.min_leafs) or (np.shape(mat1)[0] < self.min_leafs):\n",
    "                    continue\n",
    "                new_s = self.regerr(mat0) + self.regerr(mat1)\n",
    "                if new_s < best_s: \n",
    "                    best_feat = i\n",
    "                    best_val = j\n",
    "                    best_s = new_s\n",
    "                #if S - best_s < 0.01:这个地方需要再思考下\n",
    "                    #return best_feat, best_val\n",
    "        return best_feat, best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMean(tree, i=0, flag=False):\n",
    "    \"\"\"\n",
    "    如果 树的两个分支都不是树的话，求均值就可以了。 value 为none时 label_class一定不为none, 否则已经结束\n",
    "    \"\"\"\n",
    "    if tree.right_tree.value is not None:\n",
    "        tree.right_tree.label_class = getMean(tree.right_tree, i=i+1)\n",
    "    if tree.left_tree.value is not None:\n",
    "        tree.left_tree.label_class = getMean(tree.left_tree, i=i+1)\n",
    "    means = (tree.right_tree.label_class + tree.left_tree.label_class) / 2.0\n",
    "    print(\"level is {} and value is {}\".format(i, means))\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binsplitdata(data, feature, value):\n",
    "    mat0 = data[data[:, feature] > value, : ]\n",
    "    mat1 = data[data[:, feature] <= value, : ]\n",
    "    return mat0, mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myprune(tree, testData, min_leafs=10, diff_err=10):\n",
    "    if np.shape(testData)[0] < min_leafs:\n",
    "        # 这里是有一定的合理性的\n",
    "        tree.label_class = getMean(tree)\n",
    "        tree.right_tree = None\n",
    "        tree.left_tree = None\n",
    "        tree.value = None\n",
    "        tree.feature = None\n",
    "        return tree\n",
    "    \n",
    "    if tree.feature is not None:\n",
    "        lSet, rSet = binsplitdata(testData, tree.feature, tree.value)\n",
    "        \n",
    "    if tree.left_tree.label_class is None and tree.left_tree.value is not None: # and lSet.shape[0] > min_leafs:\n",
    "        tree.left_tree = myprune(tree.left_tree, lSet)\n",
    "        \n",
    "    if tree.right_tree.label_class is None and tree.right_tree.value is not None:# and rSet.shape[0] > min_leafs:\n",
    "        tree.right_tree = myprune(tree.right_tree, rSet)\n",
    "        \n",
    "    #if tree.left_tree is not None and not tree.right_tree is not None and tree.left_tree.label_class is not None and tree.right_tree.label_class is not None:\n",
    "    if tree.left_tree.label_class is not None and tree.right_tree.label_class is not None:\n",
    "        lSet, rSet = binsplitdata(testData, tree.feature, tree.value)\n",
    "        errorNoMerge = sum(np.power(lSet[:,-1] - tree.left_tree.label_class,2)) + sum(np.power(rSet[:,-1] - tree.right_tree.label_class, 2.0))\n",
    "        \n",
    "        # 这里注意 有点意思\n",
    "        #treeMean = (tree['left'] + tree['right']) / 2.0\n",
    "        treeMean = (tree.left_tree.label_class + tree.right_tree.label_class) / 2.0\n",
    "        \n",
    "        # 合并之后的 的 方差\n",
    "        errorMerge = sum(np.power(testData[:,-1] - treeMean, 2))\n",
    "        m, n = testData.shape\n",
    "        print(\"errormerge {}, errornomerge {} m is {} ---\".format(errorMerge / m, errorNoMerge/m, m))\n",
    "        print((errorMerge - errorNoMerge) / m, \"means\")\n",
    "        if (errorMerge - errorNoMerge) / m < diff_err:\n",
    "        #if errorMerge < errorNoMerge:\n",
    "            print(\"merging\")\n",
    "            tree.label_class = treeMean\n",
    "            tree.right_tree = None\n",
    "            tree.left_tree = None\n",
    "            tree.value = None\n",
    "            tree.feature = None\n",
    "            return tree\n",
    "        else:\n",
    "            return tree\n",
    "    else:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "level is 1 and value is 25.709386021612325\n",
      "level is 1 and value is 20.80591948217272\n",
      "level is 0 and value is 23.257652751892522\n",
      "level is 2 and value is 20.221109115918708\n",
      "level is 1 and value is 18.992399305288814\n",
      "level is 0 and value is 16.4784844509121\n",
      "errormerge 17.122145973675455, errornomerge 22.903938705279433 m is 12 ---\n",
      "-5.7817927316039786 means\n",
      "merging\n",
      "errormerge 29.989426201098308, errornomerge 17.122145973675455 m is 12 ---\n",
      "12.867280227422851 means\n",
      "level is 2 and value is 11.648435573537048\n",
      "level is 1 and value is 13.936585063628122\n",
      "level is 0 and value is 15.982687175850796\n",
      "level is 0 and value is 16.854483454725486\n",
      "level is 0 and value is 13.849750309495343\n",
      "errormerge 15.231256127905898, errornomerge 9.491255638130372 m is 10 ---\n",
      "5.7400004897755235 means\n",
      "merging\n",
      "errormerge 18.81743429892902, errornomerge 16.49288261068627 m is 12 ---\n",
      "2.3245516882427495 means\n",
      "merging\n",
      "errormerge 18.969043834889288, errornomerge 18.81743429892902 m is 12 ---\n",
      "0.15160953596026872 means\n",
      "merging\n",
      "errormerge 21.005042075088003, errornomerge 18.25826077181159 m is 13 ---\n",
      "2.746781303276416 means\n",
      "merging\n",
      "level is 4 and value is 5.416028860238969\n",
      "level is 3 and value is 6.9796492336779\n",
      "level is 2 and value is 8.241681076217795\n",
      "level is 1 and value is 9.751884847604655\n",
      "level is 0 and value is 10.114698649150572\n",
      "errormerge 19.118884722241525, errornomerge 15.745326988846644 m is 22 ---\n",
      "3.3735577333948807 means\n",
      "merging\n",
      "errormerge 22.648601279479347, errornomerge 18.35521964998196 m is 23 ---\n",
      "4.293381629497387 means\n",
      "merging\n",
      "errormerge 44.27292295456994, errornomerge 30.461478047380062 m is 28 ---\n",
      "13.811444907189882 means\n"
     ]
    }
   ],
   "source": [
    "mymodel = cartreeregression(min_leafs=3)\n",
    "result = mymodel.createTree(data)\n",
    "print(mymodel.get_deep(result))\n",
    "sx = myprune(result, testdata, min_leafs=50, diff_err=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sx = myprune(result, testdata, min_leafs=10, diff_err=10)\n",
    "# mymodel.get_deep(sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a1dacb240>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.arange(len(data)), data[:, -1])\n",
    "plt.scatter(np.arange(len(data)), pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_line(model, line):\n",
    "    if model.label_class is not None:\n",
    "        return model.label_class, model\n",
    "    split_feature = model.feature\n",
    "    split_value = model.value\n",
    "    if line[split_feature] > split_value:\n",
    "         return predict_line(model.right_tree, line)\n",
    "    else:\n",
    "        return predict_line(model.left_tree, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gama(data=data, mytree=result):\n",
    "    last = {}\n",
    "    for index, line in enumerate(data):\n",
    "        x, y= line[:-1], line[-1]\n",
    "        temp_label, temp_node = predict_line(mytree, x)\n",
    "        last.setdefault(temp_node, {})\n",
    "        last[temp_node].setdefault(\"index\", []).append(index)\n",
    "        last[temp_node].setdefault(\"fz\", 0)\n",
    "        last[temp_node]['fz'] += y\n",
    "        last[temp_node].setdefault(\"fm\", 0)\n",
    "        last[temp_node]['fm'] += np.abs(y)*(2 - np.abs(y))\n",
    "    # 每个样本 对应的 gama值，每个node 下的样本的gama值一样， 用于train, ml=>gama_list\n",
    "    ml = {}\n",
    "    # 每个node 的gama值，用于预测时\n",
    "    new_last = {}\n",
    "    for key, value in last.items():\n",
    "        index_list = value['index']\n",
    "        gama = value['fz'] / value['fm']\n",
    "        new_last.setdefault(key, gama)\n",
    "        for idx in index_list:\n",
    "            ml.setdefault(idx, gama)  \n",
    "    gama_list = np.array([[int(i[0]), i[1]] for i in sorted(ml.items(), key = lambda row: row[0])])\n",
    "    return gama_list, new_last\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbdt class\n",
    "from sklearn.datasets import load_iris\n",
    "dx = load_iris()['data']\n",
    "dy = load_iris()['target']\n",
    "\n",
    "dx = dx[dy!=2]\n",
    "dy = dy[dy!=2]\n",
    "dy = np.array([-1 if i==0  else 1 for i in dy])\n",
    "\n",
    "dx = dx[: 90]\n",
    "dy = dy[: 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "mymodel = GradientBoostingClassifier(n_estimators=10)\n",
    "pred = mymodel.fit(dx, dy).predict(dx)\n",
    "acc =  (np.sum(dy == pred)) / 90\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = 0.5 * np.log((1 + np.mean(dy))/ (1 - np.mean(dy)))\n",
    "fx = np.repeat(f0, 90).reshape((90, 1))\n",
    "dy = dy.reshape((90, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / ( 1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "pred_dict.setdefault(\"init_fx\", f0)\n",
    "pred_dict['init_fx']\n",
    "\n",
    "for i in range(10):\n",
    "    dety = 2 * dy / (1 + np.exp(2 * np.multiply(dy, fx)))\n",
    "    newdata = np.concatenate([dx, dety.reshape(90, 1)], axis=1)\n",
    "    mymodel = cartreeregression(min_leafs=3)\n",
    "    result = mymodel.createTree(newdata)\n",
    "    gama_list,  mylast = get_gama(newdata, result)\n",
    "    pred_dict.setdefault(\"tree\", []).append(result)\n",
    "    pred_dict.setdefault(\"local_gama\", []).append(mylast)\n",
    "    fx = fx + gama_list[:, 1:2]\n",
    "    \n",
    "pred = [[-1] if sigmoid(i)<0.5 else [1] for i in fx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11157177565710492"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc =  (np.sum(dy == pred)) / 90\n",
    "pred_dict['init_fx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbdt_pred(myline=dx[1]):\n",
    "    init_f0 = pred_dict['init_fx']\n",
    "    tree_list = pred_dict['tree']\n",
    "    local_gama_list = pred_dict['local_gama']\n",
    "    \n",
    "    for tree, local_gama in zip(tree_list, local_gama_list):\n",
    "        p, node = predict_line(tree, myline)\n",
    "        gama = local_gama[node]\n",
    "        init_f0 += gama\n",
    "    last_pred = 1 if sigmoid(init_f0) >0.5 else -1\n",
    "    return last_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp = []\n",
    "for line in dx:\n",
    "    temp_p = gbdt_pred(line)\n",
    "    mp.append([temp_p])\n",
    "np.sum(np.array(mp)==dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree': [<__main__.treeNode at 0x1a1e091828>,\n",
       "  <__main__.treeNode at 0x1a1e091128>,\n",
       "  <__main__.treeNode at 0x1a1e0911d0>,\n",
       "  <__main__.treeNode at 0x1a1e56a588>,\n",
       "  <__main__.treeNode at 0x1a1cf9d710>,\n",
       "  <__main__.treeNode at 0x1a1d984320>,\n",
       "  <__main__.treeNode at 0x1a1da3d908>,\n",
       "  <__main__.treeNode at 0x1a1d8888d0>,\n",
       "  <__main__.treeNode at 0x1a1e650f28>,\n",
       "  <__main__.treeNode at 0x1a1e9a5278>],\n",
       " 'local_gama': [{<__main__.treeNode at 0x1a1e091f60>: -0.5000000000000133,\n",
       "   <__main__.treeNode at 0x1a1e091748>: -0.5000000000000138,\n",
       "   <__main__.treeNode at 0x1a1e091a20>: -0.5000000000000138,\n",
       "   <__main__.treeNode at 0x1a1e091e48>: 0.5000000000000138,\n",
       "   <__main__.treeNode at 0x1a1e0915c0>: 0.5000000000000134,\n",
       "   <__main__.treeNode at 0x1a1e091630>: 0.5000000000000138},\n",
       "  {<__main__.treeNode at 0x1a1e56aac8>: -0.500000000000005,\n",
       "   <__main__.treeNode at 0x1a1e56a860>: -0.5000000000000051,\n",
       "   <__main__.treeNode at 0x1a1e56a550>: 0.5000000000000051,\n",
       "   <__main__.treeNode at 0x1a1e56a4a8>: 0.500000000000005,\n",
       "   <__main__.treeNode at 0x1a1e56a908>: 0.500000000000005},\n",
       "  {<__main__.treeNode at 0x1a1cc40160>: -0.5000000000000021,\n",
       "   <__main__.treeNode at 0x1a1e56a9e8>: -0.5000000000000019,\n",
       "   <__main__.treeNode at 0x1a1cf6cba8>: -0.500000000000002,\n",
       "   <__main__.treeNode at 0x1a1cf82ef0>: 0.5000000000000018,\n",
       "   <__main__.treeNode at 0x1a1cf82e10>: 0.5000000000000018,\n",
       "   <__main__.treeNode at 0x1a1cf6cd68>: 0.5000000000000019},\n",
       "  {<__main__.treeNode at 0x1a1cfdddd8>: -0.5000000000000006,\n",
       "   <__main__.treeNode at 0x1a1cf9db00>: -0.5000000000000007,\n",
       "   <__main__.treeNode at 0x1a1cfdd668>: -0.5000000000000007,\n",
       "   <__main__.treeNode at 0x1a1d984c50>: 0.5000000000000007,\n",
       "   <__main__.treeNode at 0x1a1d984da0>: 0.5000000000000007,\n",
       "   <__main__.treeNode at 0x1a1c8d2fd0>: 0.5000000000000007},\n",
       "  {<__main__.treeNode at 0x1a1d984ac8>: -0.5000000000000007,\n",
       "   <__main__.treeNode at 0x1a1d984b00>: -0.5000000000000002,\n",
       "   <__main__.treeNode at 0x1a1d984128>: -0.5000000000000004,\n",
       "   <__main__.treeNode at 0x1a1da3d978>: 0.5000000000000003,\n",
       "   <__main__.treeNode at 0x1a1da3d710>: 0.5000000000000008,\n",
       "   <__main__.treeNode at 0x1a1da3d400>: 0.5000000000000002},\n",
       "  {<__main__.treeNode at 0x1a1e0b4ac8>: -0.5,\n",
       "   <__main__.treeNode at 0x1a1cb727b8>: -0.5000000000000002,\n",
       "   <__main__.treeNode at 0x1a1e0b4c50>: -0.5000000000000001,\n",
       "   <__main__.treeNode at 0x1a1d888a58>: 0.5000000000000001,\n",
       "   <__main__.treeNode at 0x1a1d888710>: 0.5000000000000001,\n",
       "   <__main__.treeNode at 0x1a1dfa1c88>: 0.5000000000000001},\n",
       "  {<__main__.treeNode at 0x1a1de7e198>: -0.5,\n",
       "   <__main__.treeNode at 0x1a1d888e80>: -0.5000000000000001,\n",
       "   <__main__.treeNode at 0x1a1d877668>: -0.5,\n",
       "   <__main__.treeNode at 0x1a1e0c66a0>: 0.5000000000000001,\n",
       "   <__main__.treeNode at 0x1a1e0c64e0>: 0.5,\n",
       "   <__main__.treeNode at 0x1a1e0c6278>: 0.5000000000000001},\n",
       "  {<__main__.treeNode at 0x1a1e961cf8>: -0.5,\n",
       "   <__main__.treeNode at 0x1a1e6508d0>: -0.5,\n",
       "   <__main__.treeNode at 0x1a1e9a5c18>: -0.5,\n",
       "   <__main__.treeNode at 0x1a1e9a52e8>: 0.5,\n",
       "   <__main__.treeNode at 0x1a1e9a5f28>: 0.5,\n",
       "   <__main__.treeNode at 0x1a1e9a56a0>: 0.5},\n",
       "  {<__main__.treeNode at 0x1a1ea9a0f0>: -0.5,\n",
       "   <__main__.treeNode at 0x1a1e9a5128>: -0.5,\n",
       "   <__main__.treeNode at 0x1a1e959f98>: -0.5,\n",
       "   <__main__.treeNode at 0x1a1e9596a0>: 0.5,\n",
       "   <__main__.treeNode at 0x1a1e959518>: 0.5,\n",
       "   <__main__.treeNode at 0x1a1e959b00>: 0.5},\n",
       "  {<__main__.treeNode at 0x1a1e9b1128>: -0.5,\n",
       "   <__main__.treeNode at 0x1a1e9594e0>: -0.5,\n",
       "   <__main__.treeNode at 0x1a1e9b17b8>: -0.5,\n",
       "   <__main__.treeNode at 0x1a1e9b1d30>: 0.5,\n",
       "   <__main__.treeNode at 0x1a1e9b1c88>: 0.5,\n",
       "   <__main__.treeNode at 0x1a1e9b1898>: 0.5}]}"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = dx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.9, 3. , 1.4, 0.2])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, node = predict_line(pred_dict['tree'], td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6683026279191153e-05"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.treeNode at 0x1a1d89c208>"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -0.07061618833133959,\n",
       " 1: -0.07061618833133959,\n",
       " 2: -0.07061618833133959,\n",
       " 3: -0.07061618833133959,\n",
       " 4: -0.07061618833133959,\n",
       " 5: -0.07061618833133959,\n",
       " 6: -0.07061618833133959,\n",
       " 7: -0.07061618833133959,\n",
       " 8: -0.07061618833133959,\n",
       " 9: -0.07061618833133959,\n",
       " 10: -0.07061618833133959,\n",
       " 11: -0.07061618833133959,\n",
       " 12: -0.07061618833133959,\n",
       " 13: -0.07061618833133959,\n",
       " 14: -0.07061618833133959,\n",
       " 15: -0.07061618833133959,\n",
       " 16: -0.07061618833133959,\n",
       " 17: -0.07061618833133959,\n",
       " 18: -0.07061618833133959,\n",
       " 19: -0.07061618833133959,\n",
       " 20: -0.07061618833133959,\n",
       " 21: -0.07061618833133959,\n",
       " 22: -0.07061618833133959,\n",
       " 23: -0.07061618833133959,\n",
       " 24: -0.07061618833133959,\n",
       " 25: -0.07061618833133959,\n",
       " 26: -0.07061618833133959,\n",
       " 27: -0.07061618833133959,\n",
       " 28: -0.07061618833133959,\n",
       " 29: -0.07061618833133959,\n",
       " 30: -0.07061618833133959,\n",
       " 31: -0.07061618833133959,\n",
       " 32: -0.07061618833133959,\n",
       " 33: -0.07061618833133959,\n",
       " 34: -0.07061618833133959,\n",
       " 35: -0.07061618833133959,\n",
       " 36: -0.07061618833133959,\n",
       " 37: -0.07061618833133959,\n",
       " 38: -0.07061618833133959,\n",
       " 39: -0.07061618833133959,\n",
       " 40: -0.07061618833133959,\n",
       " 41: -0.07061618833133959,\n",
       " 42: -0.07061618833133959,\n",
       " 43: -0.07061618833133959,\n",
       " 44: -0.07061618833133959,\n",
       " 45: -0.07061618833133959,\n",
       " 46: -0.07061618833133959,\n",
       " 47: -0.07061618833133959,\n",
       " 48: -0.07061618833133959,\n",
       " 49: -0.07061618833133959,\n",
       " 50: -0.07061618833133959,\n",
       " 51: -0.07061618833133959,\n",
       " 52: -0.07061618833133959,\n",
       " 53: -0.07061618833133959,\n",
       " 54: -0.07061618833133959,\n",
       " 55: -0.07061618833133959,\n",
       " 56: -0.07061618833133959,\n",
       " 57: -0.07061618833133959,\n",
       " 58: -0.07061618833133959,\n",
       " 59: -0.07061618833133959,\n",
       " 60: -0.07061618833133959,\n",
       " 61: -0.07061618833133959,\n",
       " 62: -0.07061618833133959,\n",
       " 63: -0.07061618833133959,\n",
       " 64: -0.07061618833133959,\n",
       " 65: -0.07061618833133959,\n",
       " 66: -0.07061618833133959,\n",
       " 67: -0.07061618833133959,\n",
       " 68: -0.07061618833133959,\n",
       " 69: -0.07061618833133959,\n",
       " 70: -0.07061618833133959,\n",
       " 71: -0.07061618833133959,\n",
       " 72: -0.07061618833133959,\n",
       " 73: -0.07061618833133959,\n",
       " 74: -0.07061618833133959,\n",
       " 75: -0.07061618833133959,\n",
       " 76: -0.07061618833133959,\n",
       " 77: -0.07061618833133959,\n",
       " 78: -0.07061618833133959,\n",
       " 79: -0.07061618833133959,\n",
       " 80: -0.07061618833133959,\n",
       " 81: -0.07061618833133959,\n",
       " 82: -0.07061618833133959,\n",
       " 83: -0.07061618833133959,\n",
       " 84: -0.07061618833133959,\n",
       " 85: -0.07061618833133959,\n",
       " 86: -0.07061618833133959,\n",
       " 87: -0.07061618833133959,\n",
       " 88: -0.07061618833133959,\n",
       " 89: -0.07061618833133959,\n",
       " 90: -0.07061618833133959,\n",
       " 91: -0.07061618833133959,\n",
       " 92: -0.07061618833133959,\n",
       " 93: -0.07061618833133959,\n",
       " 94: -0.07061618833133959,\n",
       " 95: -0.07061618833133959,\n",
       " 96: -0.07061618833133959,\n",
       " 97: -0.07061618833133959,\n",
       " 98: -0.07061618833133959,\n",
       " 99: -0.07061618833133959,\n",
       " 100: -0.07061618833133959,\n",
       " 101: -0.07061618833133959,\n",
       " 102: -0.07061618833133959,\n",
       " 103: -0.07061618833133959,\n",
       " 104: -0.07061618833133959,\n",
       " 105: -0.07061618833133959,\n",
       " 106: -0.07061618833133959,\n",
       " 107: -0.07061618833133959,\n",
       " 108: -0.07061618833133959,\n",
       " 109: -0.07061618833133959,\n",
       " 110: -0.07061618833133959,\n",
       " 111: -0.07061618833133959,\n",
       " 112: -0.07061618833133959,\n",
       " 113: -0.07061618833133959,\n",
       " 114: -0.07061618833133959,\n",
       " 115: -0.07061618833133959,\n",
       " 116: -0.07061618833133959,\n",
       " 117: -0.07061618833133959,\n",
       " 118: -0.07061618833133959,\n",
       " 119: -0.07061618833133959,\n",
       " 120: -0.07061618833133959,\n",
       " 121: -0.07061618833133959,\n",
       " 122: -0.07061618833133959,\n",
       " 123: -0.07061618833133959,\n",
       " 124: -0.07061618833133959,\n",
       " 125: -0.07061618833133959,\n",
       " 126: -0.07061618833133959,\n",
       " 127: -0.07061618833133959,\n",
       " 128: -0.07061618833133959,\n",
       " 129: -0.07061618833133959,\n",
       " 130: -0.07061618833133959,\n",
       " 131: -0.07061618833133959,\n",
       " 132: -0.07061618833133959,\n",
       " 133: -0.07061618833133959,\n",
       " 134: -0.07061618833133959,\n",
       " 135: -0.07061618833133959,\n",
       " 136: -0.07061618833133959,\n",
       " 137: -0.07061618833133959,\n",
       " 138: -0.07061618833133959,\n",
       " 139: -0.07061618833133959,\n",
       " 140: -0.07061618833133959,\n",
       " 141: -0.07061618833133959,\n",
       " 142: -0.07061618833133959,\n",
       " 143: -0.07061618833133959,\n",
       " 144: -0.07061618833133959,\n",
       " 145: -0.07061618833133959,\n",
       " 146: -0.07061618833133959,\n",
       " 147: -0.07061618833133959,\n",
       " 148: -0.07061618833133959,\n",
       " 149: -0.07061618833133959,\n",
       " 150: -0.07061618833133959,\n",
       " 151: -0.07061618833133959,\n",
       " 152: -0.07061618833133959,\n",
       " 153: -0.07061618833133959,\n",
       " 154: -0.07061618833133959,\n",
       " 155: -0.07061618833133959,\n",
       " 156: -0.07061618833133959,\n",
       " 157: -0.07061618833133959,\n",
       " 158: -0.07061618833133959,\n",
       " 159: -0.07061618833133959,\n",
       " 160: -0.07061618833133959,\n",
       " 161: -0.07061618833133959,\n",
       " 162: -0.07061618833133959,\n",
       " 163: -0.07061618833133959,\n",
       " 164: -0.07061618833133959,\n",
       " 165: -0.07061618833133959,\n",
       " 166: -0.07061618833133959,\n",
       " 167: -0.07061618833133959,\n",
       " 168: -0.07061618833133959,\n",
       " 169: -0.07061618833133959,\n",
       " 170: -0.07061618833133959,\n",
       " 171: -0.07061618833133959,\n",
       " 172: -0.07061618833133959,\n",
       " 173: -0.07061618833133959,\n",
       " 174: -0.07061618833133959,\n",
       " 175: -0.07061618833133959,\n",
       " 176: -0.07061618833133959,\n",
       " 177: -0.07061618833133959,\n",
       " 178: -0.07061618833133959,\n",
       " 179: -0.07061618833133959,\n",
       " 180: -0.07061618833133959,\n",
       " 181: -0.07061618833133959,\n",
       " 182: -0.07061618833133959,\n",
       " 183: -0.07061618833133959,\n",
       " 184: -0.07061618833133959,\n",
       " 185: -0.07061618833133959,\n",
       " 186: -0.07061618833133959,\n",
       " 187: -0.07061618833133959,\n",
       " 188: -0.07061618833133959,\n",
       " 189: -0.07061618833133959,\n",
       " 190: -0.07061618833133959,\n",
       " 191: -0.07061618833133959,\n",
       " 192: -0.07061618833133959,\n",
       " 193: -0.07061618833133959,\n",
       " 194: -0.07061618833133959,\n",
       " 195: -0.07061618833133959,\n",
       " 196: -0.07061618833133959,\n",
       " 197: -0.07061618833133959,\n",
       " 198: -0.07061618833133959,\n",
       " 199: -0.07061618833133959}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07061618833133959"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylast[node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn gbdt acc is 1.0\n",
      "-1\n",
      "gbdt_acc is 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#from test.treeRegression import CartreeRegression\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class GbdtTree(cartreeregression):\n",
    "    def __init__(self, n_trees=10):\n",
    "        super(GbdtTree, self).__init__()\n",
    "        self.n_trees = n_trees\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def predict_line(self, model, line):\n",
    "        if model.label_class is not None:\n",
    "            return model.label_class, model\n",
    "        split_feature = model.feature\n",
    "        split_value = model.value\n",
    "        if line[split_feature] > split_value:\n",
    "            return self.predict_line(model.right_tree, line)\n",
    "        else:\n",
    "            return self.predict_line(model.left_tree, line)\n",
    "\n",
    "    def get_gama(self, data, mytree):\n",
    "        last = {}\n",
    "        for index, line in enumerate(data):\n",
    "            x, y = line[:-1], line[-1]\n",
    "            temp_label, temp_node = self.predict_line(mytree, x)\n",
    "            last.setdefault(temp_node, {})\n",
    "            last[temp_node].setdefault(\"index\", []).append(index)\n",
    "            last[temp_node].setdefault(\"fz\", 0)\n",
    "            last[temp_node]['fz'] += y\n",
    "            last[temp_node].setdefault(\"fm\", 0)\n",
    "            last[temp_node]['fm'] += np.abs(y) * (2 - np.abs(y))\n",
    "\n",
    "        # 每个样本 对应的 gama值，每个node 下的样本的gama值一样， 用于train, ml=>gama_list\n",
    "        ml = {}\n",
    "        # 每个node 的gama值，用于预测时\n",
    "        new_last = {}\n",
    "        for key, value in last.items():\n",
    "            index_list = value['index']\n",
    "            gama = value['fz'] / value['fm']\n",
    "            new_last.setdefault(key, gama)\n",
    "            for idx in index_list:\n",
    "                ml.setdefault(idx, gama)\n",
    "        gama_list = np.array([[int(i[0]), i[1]] for i in sorted(ml.items(), key=lambda row: row[0])])\n",
    "        return gama_list, new_last\n",
    "\n",
    "    def fit(self, data, target):\n",
    "        m, n = data.shape\n",
    "\n",
    "        if len(target.shape) != 2:\n",
    "            target = target.reshape(m, 1)\n",
    "\n",
    "        # 初始化某些值\n",
    "        f0 = 0.5 * np.log((1 + np.mean(target))/(1 - np.mean(target)))\n",
    "        fx = np.repeat(f0, m).reshape((m, 1))\n",
    "\n",
    "        pred_dict = {}\n",
    "        pred_dict.setdefault(\"init_fx\", f0)\n",
    "\n",
    "        for i in range(self.n_trees):\n",
    "            dety = 2 * target / (1 + np.exp(2 * np.multiply(target, fx)))\n",
    "            newdata = np.concatenate([data, dety.reshape(m, 1)], axis=1)\n",
    "            mymodel = cartreeregression(min_leafs=3)\n",
    "            mytree = mymodel.createTree(newdata)\n",
    "            gama_list, node_gama = self.get_gama(newdata, mytree)\n",
    "            fx = fx + gama_list[:, 1:2]\n",
    "            #存储模型的参数\n",
    "            pred_dict.setdefault(\"tree\", []).append(mytree)\n",
    "            pred_dict.setdefault(\"local_gama\", []).append(node_gama)\n",
    "        self.gdbt_modelparamter = pred_dict\n",
    "        return self\n",
    "\n",
    "    def gbdt_predict_line(self, line):\n",
    "        init_f0 = self.gdbt_modelparamter['init_fx']\n",
    "        tree_list = self.gdbt_modelparamter['tree']\n",
    "        local_gama_list = self.gdbt_modelparamter['local_gama']\n",
    "\n",
    "        for tree, local_gama in zip(tree_list, local_gama_list):\n",
    "            temp_pred, node = self.predict_line(tree, line)\n",
    "            gama = local_gama[node]\n",
    "            init_f0 += gama\n",
    "        last_pred = 1 if self.sigmoid(init_f0) > 0.5 else -1\n",
    "        return last_pred\n",
    "\n",
    "    def gbdt_predict(self, data):\n",
    "        predicts = []\n",
    "        for line in data:\n",
    "            temp_pred = self.gbdt_predict_line(line)\n",
    "            predicts.append(temp_pred)\n",
    "        return np.array(predicts)\n",
    "\n",
    "    @property\n",
    "    def gbdtmodel(self):\n",
    "        return self.gdbt_modelparamter\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from sklearn.datasets import load_iris\n",
    "\n",
    "    dx = load_iris()['data']\n",
    "    dy = load_iris()['target']\n",
    "    dx = dx[dy != 2]\n",
    "    dy = dy[dy != 2]\n",
    "    dy = np.array([-1 if i == 0  else 1 for i in dy])\n",
    "    dx = dx[: 90]\n",
    "    dy = dy[: 90]\n",
    "    m, n = dx.shape\n",
    "\n",
    "    # first_test\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    mymodel = GradientBoostingClassifier(n_estimators=10)\n",
    "    pred = mymodel.fit(dx, dy).predict(dx)\n",
    "    acc = (np.sum(dy == pred)) / m\n",
    "    print(\"sklearn gbdt acc is {}\".format(acc))\n",
    "\n",
    "    # second test\n",
    "    gbdtmodel = GbdtTree()\n",
    "    mymodel = gbdtmodel.fit(dx, dy)\n",
    "    one_pred = gbdtmodel.gbdt_predict_line(dx[0])\n",
    "    print(one_pred)\n",
    "\n",
    "    pred = gbdtmodel.gbdt_predict(dx)\n",
    "    acc = (np.sum(dy == pred)) / m\n",
    "    print(\"gbdt_acc is {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
