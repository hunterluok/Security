{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luokui/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/luokui/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>gute lage im stadtzentrum. shoppingmeile und s...</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-11-20</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>this is a fairly new property i think. it is a...</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-07-07</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>first time at this group of hotels. pretty new...</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-27</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>had continental style breakfast here a short d...</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-12-07</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>definitely not a fan. coming from orange count...</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-06-17</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           4             4   \n",
       "1           7             7   \n",
       "2           8             8   \n",
       "3          15            15   \n",
       "4          29            29   \n",
       "\n",
       "                                                text  stars        date  year  \n",
       "0  gute lage im stadtzentrum. shoppingmeile und s...      5  2013-11-20  2013  \n",
       "1  this is a fairly new property i think. it is a...      4  2013-07-07  2013  \n",
       "2  first time at this group of hotels. pretty new...      4  2013-04-27  2013  \n",
       "3  had continental style breakfast here a short d...      3  2013-12-07  2013  \n",
       "4  definitely not a fan. coming from orange count...      2  2013-06-17  2013  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('yelp_2013.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>468608.000000</td>\n",
       "      <td>468608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.671907</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.364499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               stars      year\n",
       "count  468608.000000  468608.0\n",
       "mean        3.671907    2013.0\n",
       "std         1.364499       0.0\n",
       "min         1.000000    2013.0\n",
       "25%         3.000000    2013.0\n",
       "50%         4.000000    2013.0\n",
       "75%         5.000000    2013.0\n",
       "max         5.000000    2013.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['text'][0]\n",
    "cols = ['stars','year']\n",
    "#df[cols].min(axis=1)\n",
    "df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683.7616408597378, 625.4078103577162, 5117)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = df.text.str.len()\n",
    "#lens.means(),lens.std(),lens.max()\n",
    "import numpy as np\n",
    "np.mean(lens),np.std(lens),np.max(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1232592b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFP1JREFUeJzt3X+s3XV9x/Hney1gAygF5K5pm7VmzWInG8INNGFZ7mQp\nBZYVE9hKCFRkq0HYNOsyqybDiSa4BJ2YDVOlsRgUGWraaFltgBNjIr9/FUTsBRu5tqHDIlKNuuJ7\nf5zPxcP19N4P57b3e+89z0dycr7n/f18f7wPh/u63x/3NDITSZJq/F7TOyBJmjkMDUlSNUNDklTN\n0JAkVTM0JEnVDA1JUjVDQ5JUzdCQJFUzNCRJ1eZONCAiFgO3AL8P/AbYmJmfjoiPAH8P/G8Z+qHM\n3FaW+SBwJfAK8I+Zub3UVwGfBuYAn8/M60t9KXAbcCLwMHBZZv46Io4p2z4D+Anwt5m5e7z9Pfnk\nk3PJkiW1/b/Gz3/+c4499tielp2J+qnffuoV+qvffuoVjly/Dz300AuZ+eYJB2bmuA9gAXB6mT4e\n+AGwHPgI8M9dxi8HHgOOAZYCz9AOiTll+i3A0WXM8rLM7cCaMv1Z4Koy/V7gs2V6DfCVifb3jDPO\nyF7dc889PS87E/VTv/3Ua2Z/9dtPvWYeuX6BB3OCn6+ZOfHpqczcm5kPl+mXgaeAheMsshq4LTN/\nlZk/BIaBM8tjODOfzcxf0z6yWB0RAbwDuKMsvxm4sGNdm8v0HcA5ZbwkqQGv65pGRCwB3g7cV0rX\nRMTjEbEpIuaX2kLguY7FRkrtUPWTgJ9m5sEx9desq8x/qYyXJDVgwmsaoyLiOOCrwPsz82cRcRNw\nHZDl+Qbg3UC3I4Gke0DlOOOZYF7nvq0D1gEMDAzQarXG7eVQDhw40POyM1E/9dtPvUJ/9dtPvULz\n/VaFRkQcRTswbs3MrwFk5vMd8z8HfKO8HAEWdyy+CNhTprvVXwBOiIi55Wiic/zoukYiYi7wJmD/\n2P3LzI3ARoDBwcEcGhqqaet3tFotel12JuqnfvupV+ivfvupV2i+3wlPT5VrCDcDT2XmJzvqCzqG\nvRN4okxvBdZExDHlrqhlwP3AA8CyiFgaEUfTvrC9tVyAuQe4qCy/FtjSsa61Zfoi4O4yXpLUgJoj\njbOBy4CdEfFoqX0IuCQiTqN9umg38B6AzHwyIm4HvgccBK7OzFcAIuIaYDvtO6k2ZeaTZX0fAG6L\niI8Bj9AOKcrzFyNimPYRxppJ9CpJmqQJQyMzv0P3awvbxlnm48DHu9S3dVsuM5+lfXfV2PovgYsn\n2kdJ0tTwL8IlSdUMDUlStepbbvvBzh+/xLs2fLORbe++/oJGtitJr4dHGpKkaoaGJKmaoSFJqmZo\nSJKqGRqSpGqGhiSpmqEhSapmaEiSqhkakqRqhoYkqZqhIUmqZmhIkqoZGpKkaoaGJKmaoSFJqmZo\nSJKqGRqSpGqGhiSpmqEhSapmaEiSqhkakqRqhoYkqZqhIUmqZmhIkqoZGpKkaoaGJKmaoSFJqmZo\nSJKqGRqSpGqGhiSpmqEhSao2YWhExOKIuCcinoqIJyPifaV+YkTsiIhd5Xl+qUdE3BgRwxHxeESc\n3rGutWX8rohY21E/IyJ2lmVujIgYbxuSpGbUHGkcBNZn5luBFcDVEbEc2ADclZnLgLvKa4DzgGXl\nsQ64CdoBAFwLnAWcCVzbEQI3lbGjy60q9UNtQ5LUgAlDIzP3ZubDZfpl4ClgIbAa2FyGbQYuLNOr\ngVuy7V7ghIhYAJwL7MjM/Zn5IrADWFXmvTEzv5uZCdwyZl3dtiFJasDruqYREUuAtwP3AQOZuRfa\nwQKcUoYtBJ7rWGyk1Marj3SpM842JEkNmFs7MCKOA74KvD8zf1YuO3Qd2qWWPdSrRcQ62qe3GBgY\noNVqvZ7FXzUwD9aferCnZSer132ejAMHDjSy3Sb0U6/QX/32U6/QfL9VoRERR9EOjFsz82ul/HxE\nLMjMveUU075SHwEWdyy+CNhT6kNj6q1SX9Rl/HjbeI3M3AhsBBgcHMyhoaFuwyb0mVu3cMPO6hw9\nrHZfOjTl22y1WvT6Xs00/dQr9Fe//dQrNN9vzd1TAdwMPJWZn+yYtRUYvQNqLbClo355uYtqBfBS\nObW0HVgZEfPLBfCVwPYy7+WIWFG2dfmYdXXbhiSpATW/Vp8NXAbsjIhHS+1DwPXA7RFxJfAj4OIy\nbxtwPjAM/AK4AiAz90fEdcADZdxHM3N/mb4K+AIwD7izPBhnG5KkBkwYGpn5HbpfdwA4p8v4BK4+\nxLo2AZu61B8E3tal/pNu25AkNcO/CJckVTM0JEnVDA1JUjVDQ5JUzdCQJFUzNCRJ1QwNSVI1Q0OS\nVM3QkCRVMzQkSdUMDUlSNUNDklTN0JAkVTM0JEnVDA1JUjVDQ5JUzdCQJFUzNCRJ1QwNSVI1Q0OS\nVM3QkCRVMzQkSdUMDUlSNUNDklTN0JAkVTM0JEnVDA1JUjVDQ5JUzdCQJFUzNCRJ1QwNSVI1Q0OS\nVM3QkCRVMzQkSdUmDI2I2BQR+yLiiY7aRyLixxHxaHmc3zHvgxExHBFPR8S5HfVVpTYcERs66ksj\n4r6I2BURX4mIo0v9mPJ6uMxfcrialiT1puZI4wvAqi71T2XmaeWxDSAilgNrgD8uy/xXRMyJiDnA\nfwLnAcuBS8pYgE+UdS0DXgSuLPUrgRcz8w+BT5VxkqQGTRgamfltYH/l+lYDt2XmrzLzh8AwcGZ5\nDGfms5n5a+A2YHVEBPAO4I6y/Gbgwo51bS7TdwDnlPGSpIbMncSy10TE5cCDwPrMfBFYCNzbMWak\n1ACeG1M/CzgJ+GlmHuwyfuHoMpl5MCJeKuNfGLsjEbEOWAcwMDBAq9XqqaGBebD+1IMTDzwCet3n\nyThw4EAj221CP/UK/dVvP/UKzffba2jcBFwHZHm+AXg30O1IIOl+RJPjjGeCea8tZm4ENgIMDg7m\n0NDQOLt+aJ+5dQs37JxMjvZu96VDU77NVqtFr+/VTNNPvUJ/9dtPvULz/fZ091RmPp+Zr2Tmb4DP\n0T79BO0jhcUdQxcBe8apvwCcEBFzx9Rfs64y/03UnyaTJB0BPYVGRCzoePlOYPTOqq3AmnLn01Jg\nGXA/8ACwrNwpdTTti+VbMzOBe4CLyvJrgS0d61pbpi8C7i7jJUkNmfBcTER8GRgCTo6IEeBaYCgi\nTqN9umg38B6AzHwyIm4HvgccBK7OzFfKeq4BtgNzgE2Z+WTZxAeA2yLiY8AjwM2lfjPwxYgYpn2E\nsWbS3UqSJmXC0MjMS7qUb+5SGx3/ceDjXerbgG1d6s/y29NbnfVfAhdPtH+SpKnjX4RLkqoZGpKk\naoaGJKmaoSFJqmZoSJKqGRqSpGqGhiSpmqEhSarWzLfz6Xcs2fDNKd/m+lMPMjTlW5U0k3mkIUmq\nZmhIkqoZGpKkaoaGJKmaoSFJqmZoSJKqGRqSpGqGhiSpmqEhSapmaEiSqhkakqRqhoYkqZqhIUmq\nZmhIkqoZGpKkaoaGJKmaoSFJqmZoSJKqGRqSpGqGhiSpmqEhSapmaEiSqhkakqRqhoYkqZqhIUmq\nNmFoRMSmiNgXEU901E6MiB0Rsas8zy/1iIgbI2I4Ih6PiNM7lllbxu+KiLUd9TMiYmdZ5saIiPG2\nIUlqTs2RxheAVWNqG4C7MnMZcFd5DXAesKw81gE3QTsAgGuBs4AzgWs7QuCmMnZ0uVUTbEOS1JAJ\nQyMzvw3sH1NeDWwu05uBCzvqt2TbvcAJEbEAOBfYkZn7M/NFYAewqsx7Y2Z+NzMTuGXMurptQ5LU\nkLk9LjeQmXsBMnNvRJxS6guB5zrGjZTaePWRLvXxtvE7ImId7aMVBgYGaLVavTU1D9aferCnZWei\ngXn0/F7NNAcOHOibXqG/+u2nXqH5fnsNjUOJLrXsof66ZOZGYCPA4OBgDg0Nvd5VAPCZW7dww87D\n/ZZMX+tPPcjf9PhezTStVotePxczUT/120+9QvP99nr31PPl1BLleV+pjwCLO8YtAvZMUF/UpT7e\nNiRJDek1NLYCo3dArQW2dNQvL3dRrQBeKqeYtgMrI2J+uQC+Ethe5r0cESvKXVOXj1lXt21Ikhoy\n4bmYiPgyMAScHBEjtO+Cuh64PSKuBH4EXFyGbwPOB4aBXwBXAGTm/oi4DnigjPtoZo5eXL+K9h1a\n84A7y4NxtiFJasiEoZGZlxxi1jldxiZw9SHWswnY1KX+IPC2LvWfdNuGJKk5/kW4JKmaoSFJqmZo\nSJKqGRqSpGqGhiSpmqEhSapmaEiSqhkakqRqhoYkqZqhIUmqZmhIkqoZGpKkaoaGJKmaoSFJqmZo\nSJKqGRqSpGqGhiSpmqEhSapmaEiSqhkakqRqhoYkqZqhIUmqZmhIkqoZGpKkaoaGJKmaoSFJqmZo\nSJKqGRqSpGqGhiSpmqEhSapmaEiSqhkakqRqhoYkqdqkQiMidkfEzoh4NCIeLLUTI2JHROwqz/NL\nPSLixogYjojHI+L0jvWsLeN3RcTajvoZZf3DZdmYzP5KkibncBxp/EVmnpaZg+X1BuCuzFwG3FVe\nA5wHLCuPdcBN0A4Z4FrgLOBM4NrRoClj1nUst+ow7K8kqUdzj8A6VwNDZXoz0AI+UOq3ZGYC90bE\nCRGxoIzdkZn7ASJiB7AqIlrAGzPzu6V+C3AhcOcR2Oe+tWTDNxvZ7u7rL2hku5ImZ7JHGgl8KyIe\nioh1pTaQmXsByvMppb4QeK5j2ZFSG68+0qUuSWrIZI80zs7MPRFxCrAjIr4/zthu1yOyh/rvrrgd\nWOsABgYGaLVa4+70oQzMg/WnHuxp2ZmoyX57/W/UqwMHDkz5NpvUT/32U6/QfL+TCo3M3FOe90XE\n12lfk3g+IhZk5t5y+mlfGT4CLO5YfBGwp9SHxtRbpb6oy/hu+7ER2AgwODiYQ0ND3YZN6DO3buGG\nnUfijN30tP7Ug431u/vSoSndXqvVotfPxUzUT/32U6/QfL89n56KiGMj4vjRaWAl8ASwFRi9A2ot\nsKVMbwUuL3dRrQBeKqevtgMrI2J+uQC+Ethe5r0cESvKXVOXd6xLktSAyfyaOQB8vdwFOxf4Umb+\nT0Q8ANweEVcCPwIuLuO3AecDw8AvgCsAMnN/RFwHPFDGfXT0ojhwFfAFYB7tC+BeBJekBvUcGpn5\nLPCnXeo/Ac7pUk/g6kOsaxOwqUv9QeBtve6jJOnw8i/CJUnVDA1JUjVDQ5JUzdCQJFUzNCRJ1QwN\nSVI1Q0OSVM3QkCRVMzQkSdUMDUlSNUNDklTN0JAkVTM0JEnVDA1JUjVDQ5JUzdCQJFUzNCRJ1QwN\nSVI1Q0OSVK3nfyNcmowlG745pdtbf+pB3lW2ufv6C6Z029Js4pGGJKmaoSFJqmZoSJKqGRqSpGqG\nhiSpmqEhSapmaEiSqhkakqRqhoYkqZqhIUmq5teIqO9M9VeYjPLrSzQbeKQhSapmaEiSqhkakqRq\n0/6aRkSsAj4NzAE+n5nXN7xLUk+m8lpK51fBg9dTdPhM6yONiJgD/CdwHrAcuCQilje7V5LUv6b7\nkcaZwHBmPgsQEbcBq4HvNbpX0gzjHWM6XKZ7aCwEnut4PQKc1dC+SHqdpiKsxp6Km+3G63cqQjoy\n84hvpFcRcTFwbmb+XXl9GXBmZv7DmHHrgHXl5R8BT/e4yZOBF3pcdibqp377qVfor377qVc4cv3+\nQWa+eaJB0/1IYwRY3PF6EbBn7KDM3AhsnOzGIuLBzByc7Hpmin7qt596hf7qt596heb7ndYXwoEH\ngGURsTQijgbWAFsb3idJ6lvT+kgjMw9GxDXAdtq33G7KzCcb3i1J6lvTOjQAMnMbsG2KNjfpU1wz\nTD/120+9Qn/120+9QsP9TusL4ZKk6WW6X9OQJE0jhkYREasi4umIGI6IDU3vTy8iYlNE7IuIJzpq\nJ0bEjojYVZ7nl3pExI2l38cj4vSOZdaW8bsiYm0TvUwkIhZHxD0R8VREPBkR7yv12drvGyLi/oh4\nrPT7b6W+NCLuK/v+lXLDCBFxTHk9XOYv6VjXB0v96Yg4t5mOJhYRcyLikYj4Rnk9m3vdHRE7I+LR\niHiw1KbnZzkz+/5B+yL7M8BbgKOBx4DlTe9XD338OXA68ERH7d+BDWV6A/CJMn0+cCcQwArgvlI/\nEXi2PM8v0/Ob7q1LrwuA08v08cAPaH/VzGztN4DjyvRRwH2lj9uBNaX+WeCqMv1e4LNleg3wlTK9\nvHy+jwGWls/9nKb7O0TP/wR8CfhGeT2be90NnDymNi0/yx5ptL36dSWZ+Wtg9OtKZpTM/Dawf0x5\nNbC5TG8GLuyo35Jt9wInRMQC4FxgR2buz8wXgR3AqiO/969PZu7NzIfL9MvAU7S/QWC29puZeaC8\nPKo8EngHcEepj+139H24AzgnIqLUb8vMX2XmD4Fh2p//aSUiFgEXAJ8vr4NZ2us4puVn2dBo6/Z1\nJQsb2pfDbSAz90L7By1wSqkfqucZ916U0xFvp/3b96ztt5yueRTYR/sHwjPATzPzYBnSue+v9lXm\nvwScxMzp9z+AfwF+U16fxOztFdq/AHwrIh6K9jdcwDT9LE/7W26nSHSpzfbbyg7V84x6LyLiOOCr\nwPsz82ftXzC7D+1Sm1H9ZuYrwGkRcQLwdeCt3YaV5xnbb0T8FbAvMx+KiKHRcpehM77XDmdn5p6I\nOAXYERHfH2dso/16pNFW9XUlM9Tz5dCV8ryv1A/V84x5LyLiKNqBcWtmfq2UZ22/ozLzp0CL9vns\nEyJi9Je/zn1/ta8y/020T13OhH7PBv46InbTPlX8DtpHHrOxVwAyc0953kf7F4IzmaafZUOjbTZ/\nXclWYPQuirXAlo765eVOjBXAS+UQeDuwMiLml7s1VpbatFLOWd8MPJWZn+yYNVv7fXM5wiAi5gF/\nSfs6zj3ARWXY2H5H34eLgLuzfbV0K7Cm3HG0FFgG3D81XdTJzA9m5qLMXEL7/8W7M/NSZmGvABFx\nbEQcPzpN+zP4BNP1s9z0XQPT5UH7joQf0D5P/OGm96fHHr4M7AX+j/ZvHVfSPrd7F7CrPJ9Yxgbt\nf+DqGWAnMNixnnfTvmg4DFzRdF+H6PXPaB96Pw48Wh7nz+J+/wR4pPT7BPCvpf4W2j8Ih4H/Bo4p\n9TeU18Nl/ls61vXh8j48DZzXdG8T9D3Eb++empW9lr4eK48nR3/+TNfPsn8RLkmq5ukpSVI1Q0OS\nVM3QkCRVMzQkSdUMDUlSNUNDklTN0JAkVTM0JEnV/h9C+vGwOJdO6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122c8afd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "lens.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re,string\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'[{string.punctuation}\"\"''¨«»®´·º½¾¿¡§£₤‘’]')\n",
    "def tokenize(s):\n",
    "    return re_tok.sub(r'\\l',s).split()\n",
    "    #return re_tok.sub(r' \\1 ',s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luokui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: bad escape \\l\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/luokui/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1,2),tokenizer=tokenize,\n",
    "                      min_df=3,max_df=0.9,strip_accents='unicode', use_idf=1,\n",
    "                      smooth_idf=1, sublinear_tf=1)\n",
    "td = vec.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import  LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mdl(x,y_value):\n",
    "    y  = y_value\n",
    "    r = np.log(pr(1,y)/pr(0,y))\n",
    "    m = LogisticRegression(C=4,dual=True)\n",
    "    x_nb = np.multiply(x, r)\n",
    "    re = m.fit(x_nb, y)\n",
    "    return re,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re,r = get_mdl(x,y)\n",
    "np.exp(r)\n",
    "re.predict_proba(np.multiply(x,r))\n",
    "preds = np.zeros((len(x),len(y)))\n",
    "preds\n",
    "for i,j in enumerate(y):\n",
    "    print('fit',j)\n",
    "    preds[:,i] = re.predict_proba(np.multiply(x,r))[:,1]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df.stars.values-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luokui/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/luokui/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/luokui/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/luokui/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer,text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ = to_categorical(y,num_classes=5)\n",
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this is a fairly new property i think. it is a german company and has most of the amenities you would want. it is priced on the budget minded side so it won't break your bank.\\nlocation is really good. near the royal mile and waverley station without being too noisy. very easy to walk to everything we wanted to do. has wifi but we did have to re log in every day.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.text.values\n",
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class config:\n",
    "    def __init__(self):\n",
    "        self.max_num_words = 30000\n",
    "        self.embedding_dim = 200\n",
    "        self.validation_split = 0.1\n",
    "        self.test_split = 0.1\n",
    "        self.num_filters = 50\n",
    "        self.max_len = 512 \n",
    "        self.batch_size = 100\n",
    "        self.epochs = 10\n",
    "confs = config() #整理的括号不能少\n",
    "confs.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_num_words = 30000\n",
    "embedding_dim = 200\n",
    "validation_split = 0.1\n",
    "test_split = 0.1\n",
    "num_filters = 50\n",
    "max_len = 512 \n",
    "batch_size = 100\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([459988, 375168,  62158, ..., 342242, 322150, 107770])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "indices = np.arange(x.shape[0])\n",
    "np.random.seed(2018)\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y_ = y_[indices]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_validation_sample_val = int((validation_split + test_split)* x.shape[0])\n",
    "nb_validation_sample_test = int(test_split*x.shape[0])\n",
    "#nb_validation_sample_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#t = np.arange(10)t[-3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x[:-nb_validation_sample_val]\n",
    "y_train = y_[:-nb_validation_sample_val]\n",
    "x_val =  x[-nb_validation_sample_val:-nb_validation_sample_test]\n",
    "y_val =  y_[-nb_validation_sample_val:-nb_validation_sample_test]\n",
    "x_test = x[-nb_validation_sample_test:]\n",
    "y_test = y_[-nb_validation_sample_test:]\n",
    "# 数据存放在一个列表里，其中 每一句话 就是一个 字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del x\n",
    "del y\n",
    "del y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer1 = Tokenizer(num_words=max_num_words)\n",
    "tokenizer1.fit_on_texts(df.text)\n",
    "vocab = tokenizer1.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_word_ids = tokenizer1.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_word_ids = tokenizer1.texts_to_sequences(x_test)\n",
    "x_val_word_ids = tokenizer1.texts_to_sequences(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_val_word_ids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_padded_seqs = pad_sequences(x_train_word_ids,maxlen=max_len)\n",
    "x_test_padded_seqs = pad_sequences(x_test_word_ids,maxlen=max_len)\n",
    "x_val_padded_seqs = pad_sequences(x_val_word_ids,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del x_train_word_ids\n",
    "del x_test_word_ids\n",
    "del x_val_word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   19,  245,  158],\n",
       "       [   0,    0,    0, ..., 3491,    1,  567]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_padded_seqs[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" 不起作用啊\\ndef del_data(data_list):\\n    for i in data_list:\\n        del i\\ndata_list=['x_train_word_ids','x_test_word_ids','x_val_word_ids']\\ndel_data(data_list)\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 不起作用啊\n",
    "def del_data(data_list):\n",
    "    for i in data_list:\n",
    "        del i\n",
    "data_list=['x_train_word_ids','x_test_word_ids','x_val_word_ids']\n",
    "del_data(data_list)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data,rate=8):\n",
    "    last = []\n",
    "    m,n = data.shape\n",
    "    for i in range(m):\n",
    "        temp = np.split(data[i],rate)\n",
    "        a = []\n",
    "        for j in range(rate):\n",
    "            s = np.split(temp[j],rate)\n",
    "            a.append(s)\n",
    "        last.append(a)\n",
    "    return last\n",
    "\n",
    "x_train_padded_seqs_split = split_data(x_train_padded_seqs)\n",
    "x_test_padded_seqs_split = split_data(x_test_padded_seqs)\n",
    "x_val_padded_seqs_split = split_data(x_val_padded_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#type(x_val_padded_seqs_split[0][0][0][0])\n",
    "#x_val_padded_seqs_split[:100].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndel x_train\\ndel x_train_padded_seqs\\ndel x_test\\ndel x_test_padded_seqs\\ndel x_val\\ndel x_val_padded_seqs\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "del x_train\n",
    "del x_train_padded_seqs\n",
    "del x_test\n",
    "del x_test_padded_seqs\n",
    "del x_val\n",
    "del x_val_padded_seqs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import GRU,LSTM\n",
    "from keras.layers import  Embedding,Input,Dense\n",
    "from keras.models import Model,Sequential\n",
    "# x_val_padded_seqs_split[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import  TimeDistributed\n",
    "from keras.callbacks import  ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_52 (Embedding)     (None, 8, 200)            6000200   \n",
      "=================================================================\n",
      "Total params: 6,000,200\n",
      "Trainable params: 6,000,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.random.random((max_num_words + 1, embedding_dim))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_num_words + 1,embedding_dim,weights=[embedding_matrix],input_length=int(8),trainable=True))\n",
    "\n",
    "print_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import  Flatten,Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_107 (Embedding)    (None, 8, 200)            6000200   \n",
      "_________________________________________________________________\n",
      "time_distributed_122 (TimeDi (None, 8, 50)             10050     \n",
      "_________________________________________________________________\n",
      "gru_150 (GRU)                (None, 8, 50)             15150     \n",
      "_________________________________________________________________\n",
      "time_distributed_123 (TimeDi (None, 8, 50)             2550      \n",
      "_________________________________________________________________\n",
      "gru_151 (GRU)                (None, 8, 50)             15150     \n",
      "_________________________________________________________________\n",
      "time_distributed_124 (TimeDi (None, 8, 50)             2550      \n",
      "_________________________________________________________________\n",
      "gru_152 (GRU)                (None, 50)                15150     \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 6,061,055\n",
      "Trainable params: 6,061,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.random.random((max_num_words + 1, embedding_dim))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Embedding(max_num_words + 1,embedding_dim,weights=[embedding_matrix],input_length=int(8),trainable=True))\n",
    "model.add(Embedding(max_num_words+1,embedding_dim,input_length=8))\n",
    "model.add(TimeDistributed(Dense(50),input_shape=(8,)))\n",
    "\n",
    "model.add(GRU(num_filters,recurrent_activation='sigmoid',activation=None,return_sequences=True))\n",
    "\n",
    "#\"\"\"\n",
    "#model.add(Reshape((8,8)))\n",
    "model.add(TimeDistributed(Dense(50),input_shape=(8,8,)))\n",
    "model.add(GRU(num_filters,recurrent_activation='sigmoid',activation=None,return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributed(Dense(50),input_shape=(8,8,8,)))\n",
    "model.add(GRU(num_filters,recurrent_activation='sigmoid',activation=None,return_sequences=False))\n",
    "#\"\"\"\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "print_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_100_input to have 2 dimensions, but got array with shape (374887, 8, 8, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-727f1410aba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m model.fit(np.array(x_train_padded_seqs_split), y_train, validation_data = (np.array(x_val_padded_seqs_split), y_val),\n\u001b[0;32m---> 15\u001b[0;31m           epochs = 2, batch_size = batch_size,verbose = 1) #,callbacks = callbacks,\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_100_input to have 2 dimensions, but got array with shape (374887, 8, 8, 8)"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['acc'])\n",
    "\n",
    "\"\"\"\n",
    "savebestmodel = './save_mode/srnn_8_2_yelp2013.h5'\n",
    "#import os\n",
    "checkpoint = ModelCheckpoint(savebestmodel,monitor='val_acc',\n",
    "                            verbose=1, save_best_only=True, mode='max')\n",
    "callbacks = [checkpoint]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "model.fit(np.array(x_train_padded_seqs_split), y_train, validation_data = (np.array(x_val_padded_seqs_split), y_val),\n",
    "          epochs = 2, batch_size = batch_size,verbose = 1) #,callbacks = callbacks,\n",
    "\n",
    "\n",
    "#model.fit(np.array(x_train_padded_seqs), y_train, validation_data = (np.array(x_val_padded_seqs), y_val),\n",
    "   #       epochs = 2, batch_size = batch_size,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_46 (Embedding)     (None, 512, 200)          6000200   \n",
      "_________________________________________________________________\n",
      "gru_60 (GRU)                 (None, 50)                37650     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 6,038,105\n",
      "Trainable params: 6,038,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 374887 samples, validate on 46861 samples\n",
      "Epoch 1/2\n",
      "   500/374887 [..............................] - ETA: 1:15:55 - loss: 1.6013 - acc: 0.2720"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-dc101b4699f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m model.fit(x_train_padded_seqs, y_train, validation_data = (np.array(x_val_padded_seqs), y_val),\n\u001b[0;32m---> 20\u001b[0;31m           epochs = 2, batch_size = batch_size,callbacks = callbacks,verbose = 1)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#use the best model to evaluate on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_num_words+1,embedding_dim,input_length=512))\n",
    "model.add(GRU(num_filters,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from keras.callbacks import ModelCheckpoint             \n",
    "savebestmodel = 'save_model/SRNN(8,2)_yelp2013.h5'\n",
    "checkpoint = ModelCheckpoint(savebestmodel, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks=[checkpoint] \n",
    "\"\"\"\n",
    "             \n",
    "model.fit(x_train_padded_seqs, y_train, validation_data = (np.array(x_val_padded_seqs), y_val),\n",
    "          epochs = 2, batch_size = batch_size,callbacks = callbacks,verbose = 1)\n",
    "\n",
    "#use the best model to evaluate on test set\n",
    "# from keras.models import load_model\n",
    "# best_model= load_model(savebestmodel)          \n",
    "# print(best_model.evaluate(np.array(x_test_padded_seqs),y_test,batch_size=Batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_2 (TimeDist (None, 250, 297, 64)      640       \n",
      "=================================================================\n",
      "Total params: 640\n",
      "Trainable params: 640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import  TimeDistributed, Conv2D, Conv1D, GRU\n",
    "from keras import  Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(64, 3),input_shape=(250, 299, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_3 (TimeDist (None, 10, 64)            13056     \n",
      "=================================================================\n",
      "Total params: 13,056\n",
      "Trainable params: 13,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(TimeDistributed(GRU(64),input_shape=(10, 299, 3)))\n",
    "#model.add(GRU(64), input_shape=(10, 299, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-384"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22 *  64 * 9 - 13056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_61 (Embedding)     (None, 8.0, 200)          6000200   \n",
      "_________________________________________________________________\n",
      "gru_74 (GRU)                 (None, 50)                37650     \n",
      "=================================================================\n",
      "Total params: 6,037,850\n",
      "Trainable params: 6,037,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_______1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 8, 8)              0         \n",
      "_________________________________________________________________\n",
      "time_distributed_53 (TimeDis (None, 8, 50)             6037850   \n",
      "_________________________________________________________________\n",
      "gru_75 (GRU)                 (None, 50)                15150     \n",
      "=================================================================\n",
      "Total params: 6,053,000\n",
      "Trainable params: 6,053,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_______2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_54 (TimeDis (None, 8, 50)             6053000   \n",
      "_________________________________________________________________\n",
      "gru_76 (GRU)                 (None, 50)                15150     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 6,068,405\n",
      "Trainable params: 6,068,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "______3\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.random.random((max_num_words+1,embedding_dim))\n",
    "embedding_layer = Embedding(max_num_words+1,embedding_dim,input_length=max_len/64,\n",
    "                            weights=[embedding_matrix],trainable=True)\n",
    "\n",
    "\n",
    "input1 = Input(shape=(8,),dtype='int32')\n",
    "embed = embedding_layer(input1)\n",
    "gru1 = GRU(num_filters, recurrent_activation='sigmoid', activation=None,return_sequences=False)(embed)\n",
    "encoder1 = Model(input1, gru1)\n",
    "print_summary(encoder1)\n",
    "print(\"_______1\")\n",
    "\n",
    "input2 = Input(shape=(8,int(max_len/64),),dtype='int32')\n",
    "embed2 = TimeDistributed(encoder1)(input2)\n",
    "gru2 = GRU(num_filters,recurrent_activation='sigmoid',activation=None,return_sequences=False)(embed2)\n",
    "encoder2 = Model(input2,gru2)\n",
    "print_summary(encoder2)\n",
    "print(\"_______2\")\n",
    "\n",
    "input3 = Input(shape=(8,8,int(max_len/64)), dtype='int32')\n",
    "embed3 = TimeDistributed(encoder2)(input3)\n",
    "gru3 = GRU(num_filters,recurrent_activation='sigmoid',activation=None,return_sequences=False)(embed3)\n",
    "preds = Dense(5, activation='softmax')(gru3)\n",
    "encoder3 = Model(input3, preds)\n",
    "print_summary(encoder3)\n",
    "print(\"______3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nx = Input(shape=(12,))  # 就是shape = None,12的np.array\\ny = Dense(2,activation='softmax')(x)\\nmodel = Model(x,y)\\n\\nopt = keras.optimizers.SGD(lr=0.0001,momentum=0.9,nesterov=False)\\nmodel.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['acc'])\\n\\ntx = np.random.random((10000,12))\\nty = np.random.randint(2,size=(10000,1))\\nty = to_categorical(ty,num_classes=2)\\nmodel.fit(tx,ty,epochs=10)\\n\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "x = Input(shape=(12,))  # 就是shape = None,12的np.array\n",
    "y = Dense(2,activation='softmax')(x)\n",
    "model = Model(x,y)\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.0001,momentum=0.9,nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['acc'])\n",
    "\n",
    "tx = np.random.random((10000,12))\n",
    "ty = np.random.randint(2,size=(10000,1))\n",
    "ty = to_categorical(ty,num_classes=2)\n",
    "model.fit(tx,ty,epochs=10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
