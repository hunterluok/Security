{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 2], [3, 2, 4], [2, 1, 2], [3, 1, 2], [7, 8, 9], [2, 1, 2], [11, 1, 11]]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = [[1,1,2],[3,2,4],[2,1,2],[3,1,2],[7,8,9],[2,1,2],[11,1,11]]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 1, 2], [3, 2, 4], [2, 1, 2], [3, 1, 2], [2, 1, 2]],\n",
       " [[7, 8, 9], [11, 1, 11]],\n",
       " 0,\n",
       " array([5.9197591]))"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(data,col):\n",
    "    try:\n",
    "        feature_data = [line[col] for line in data]\n",
    "    except TypeError as e:\n",
    "        raise TypeError(\"the type is not fit de algo\")\n",
    "    feature_min_value = min(feature_data)\n",
    "    feature_max_value = max(feature_data)\n",
    "    random_value = feature_min_value + np.random.rand(1)* (feature_max_value-feature_min_value)\n",
    "    left_data = []\n",
    "    right_data = []\n",
    "    for line in data:\n",
    "        if line[col] >= random_value:\n",
    "            right_data.append(line)\n",
    "        else:\n",
    "            left_data.append(line)\n",
    "    return left_data,right_data,col,random_value\n",
    "\n",
    "\n",
    "def sample_data(data,ratio):\n",
    "    if isinstance(data,list):\n",
    "        m,n = len(data),len(data[0])\n",
    "    elif isinstance(data,np.ndarray):\n",
    "        m,n = data.shape\n",
    "    \n",
    "    if 0<ratio<1:\n",
    "        sub_m = int(ratio * m)\n",
    "    elif isinstance(ratio,int):\n",
    "        sub_m = min(ratio,m)\n",
    "    \n",
    "    new_data = []\n",
    "    random_indx = np.random.permutation(m)[:sub_m]\n",
    "    for idx in random_indx:\n",
    "        new_data.append(data[idx])\n",
    "        \n",
    "    return new_data, sub_m, n\n",
    "   \n",
    "split_data(d)\n",
    "random_data(d,ratio=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.694281332684624"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_max_deep(num):\n",
    "    return np.ceil(np.log2(num))\n",
    "\n",
    "def cost(num_items):\n",
    "    if num_items > 2:\n",
    "    # 二叉搜索树的平均路径长度。0.5772156649:欧拉常数\n",
    "        re =  (2*(np.log2(num_items-1) + 0.5772156649)-(2*(num_items-1)/num_items))\n",
    "        return re\n",
    "    elif num_items == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(data, num_col, max_deep,cur_deep = 0):\n",
    "    m,n = np.mat(data).shape\n",
    "    if cur_deep>=max_deep or m <= 1:  # 这个地方的 1 需要修稿的\n",
    "        return np.array(data).shape[0]\n",
    "\n",
    "    col = np.random.randint(num_col)\n",
    "    lSet,rSet,col,random_value = split_data(data,col)\n",
    "    retTree = {}\n",
    "    retTree['spInd'] = col\n",
    "    retTree['spVal'] = random_value\n",
    "    retTree['left'] = createTree(lSet, num_col, max_deep, cur_deep + 1)\n",
    "    retTree['right'] = createTree(rSet, num_col, max_deep, cur_deep + 1)\n",
    "    return retTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_length(tree, x): \n",
    "    split_value = tree['spVal']\n",
    "    split_ind = tree['spInd']\n",
    "    \n",
    "    if x[split_ind] > split_value:\n",
    "        if isinstance(tree['right'],dict):\n",
    "            mdeep = 1 + get_length(tree['right'], x)\n",
    "        else:\n",
    "            mdeep = cost(tree['right']) # 注意这里的平滑系数。\n",
    "    else: \n",
    "        if isinstance(tree['left'],dict):\n",
    "            mdeep = 1 + get_length(tree['left'], x)\n",
    "        else:\n",
    "            mdeep = cost(tree['left']) # 当 2为 当样本数量很少时。\n",
    "    return mdeep\n",
    "\n",
    "get_length(mytree,x = [0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def isolation_forest(data, ratio, num_trees=10):\n",
    "    Trees = []\n",
    "    sub_ms = []\n",
    "    for i in range(10):\n",
    "        random_data, sub_m, num_feature = sample_data(data,ratio)\n",
    "        max_deep = get_max_deep(sub_m)\n",
    "        ITree = createTree(random_data,num_feature, max_deep)\n",
    "        Trees.append(ITree)\n",
    "        sub_ms.append(sub_m)\n",
    "        \n",
    "    return Trees, sub_ms\n",
    "    \n",
    "#trees,sub_ms = isolation_forest(d,5)\n",
    "#trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_score(x, ITrees, data_num):\n",
    "    predictions = []\n",
    "    for itree in ITrees:\n",
    "        predict = get_length(itree, x)\n",
    "        predictions.append(predict)\n",
    "    return np.power(2,-np.sum(predictions)/len(predictions) / cost(data_num))  \n",
    "\n",
    "predict_score([100,200,300],trees,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算树的 deep 及 叶子树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tree_leafs(mytree):\n",
    "    num_feature = 0\n",
    "    for key in mytree.keys():\n",
    "        if isinstance(mytree[key],dict):\n",
    "            num_feature += tree_leafs(mytree[key])\n",
    "        else:\n",
    "            num_feature += 1 # mytree[key]\n",
    "    return num_feature\n",
    "tree_leafs(mytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tree_deep(mytree):\n",
    "    max_deep = 0\n",
    "    for key in mytree.keys():\n",
    "        if isinstance(mytree[key],dict):\n",
    "            temp_deep = tree_deep(mytree[key]) + 1\n",
    "        else:\n",
    "            temp_deep = 1   \n",
    "        max_deep = max(max_deep,temp_deep)\n",
    "    return max_deep\n",
    "tree_deep(mytree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 多叉树 ，且每个特征只使用一次，只适合 类型较少的 分类型数据。\n",
    "\n",
    "import numpy as np\n",
    "def createDataSet():\n",
    "    dataSet = [[1, 1,2, 'yes'],\n",
    "               [1, 1,3,'yes'],\n",
    "               [2, 0,1,'no'],\n",
    "               [0, 1,3,'no'],\n",
    "               [0, 1,3,'no'],\n",
    "               [2, 2,1,'yes']   \n",
    "              ]\n",
    "              #[1,1,'maybe']]\n",
    "    labels = ['no surfacing','lk','flippers']\n",
    "    return dataSet, labels\n",
    "\n",
    "data,label = createDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal(data)->\"input:最后一列带标签的数据，output:entropy\": \n",
    "    cout_dic ={}\n",
    "    if isinstance(data,list):\n",
    "        m = len(data)\n",
    "    elif isinstance(data,np.ndarray):  # 这里需要注意哦。 numpy.ndarray\n",
    "        m = data.shape[0]\n",
    "    else:\n",
    "        raise ValueError(\"The type of the data must be LIST or ARRAY\")\n",
    "    for i in range(m):\n",
    "        temp = data[i][-1]\n",
    "        cout_dic.setdefault(temp,0)\n",
    "        cout_dic[temp] +=1\n",
    "    cout_dic = {k:-(v/m)*(np.log2(v/m)) for k,v in cout_dic.items()}\n",
    "    entrop = sum(cout_dic.values())\n",
    "    return entrop\n",
    "\n",
    "cal(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, {'no': 0.25, 'yes': 0.25})"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini(data):\n",
    "    cout_dic ={}\n",
    "    m = len(data)\n",
    "    for i in range(m):\n",
    "        temp = data[i][-1]\n",
    "        cout_dic.setdefault(temp,0)\n",
    "        cout_dic[temp] +=1\n",
    "    cout_dic = {k:(v/m)**2 for k,v in cout_dic.items()}\n",
    "    gini = 1- sum(cout_dic.values())\n",
    "    return gini,cout_dic\n",
    "gini(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_feature(data,k=0):\n",
    "    m = len(data)\n",
    "    #n = len(data[0])\n",
    "    data = np.array(data)\n",
    "    t = np.unique(data[:,k])\n",
    "    splitdata={}\n",
    "    for i in t:\n",
    "        for j in range(m):\n",
    "            if data[j,k]==i:\n",
    "                splitdata.setdefault(i,[])\n",
    "                splitdata[i].append(data[j])\n",
    "    return splitdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnew_entrop=0.\\nfor key,value in xx.items():\\n    length =len(value)\\n    new_entrop +=length/5 *cal(value)\\n    #new_entrop +=cal(value)\\n    print(new_entrop)\\n'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "new_entrop=0.\n",
    "for key,value in xx.items():\n",
    "    length =len(value)\n",
    "    new_entrop +=length/5 *cal(value)\n",
    "    #new_entrop +=cal(value)\n",
    "    print(new_entrop)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "（1）计算未 划分前的entropy\n",
    "（2）根据每一个 特征的 值 进行划分，计算 entropy的改变量，选择 改变量最大的 特征和 特征值。\n",
    "（3）然后 递归的 对数据进行划分，只到满足特定的条件\n",
    "（4）计算 树的 最大深度 和枝叶数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 选择最优的分裂的枝叶。\n",
    "def chose_best_feature(data):\n",
    "    if isinstance(data,list):\n",
    "        old_entrop = cal(data)\n",
    "        n = len(data[0])-1\n",
    "        entrop_change = {}\n",
    "        len_data = len(data)\n",
    "    else:\n",
    "        raise TypeError(\"The type of the data must be List\")\n",
    "    \n",
    "    for i in range(n):\n",
    "        temp = split_feature(data,k=i)\n",
    "        new_entrop = 0.\n",
    "        for key,value in temp.items():\n",
    "            length =len(value)\n",
    "            new_entrop +=length/len_data *cal(value) #这里注意用法。 数据集划分之后 标签的 信息熵。\n",
    "        entrop_change.setdefault(i,0)\n",
    "        entrop_change[i]= old_entrop-new_entrop\n",
    "    sort_entrop_change = sorted(entrop_change.items(),key=lambda row:row[1],reverse=True)\n",
    "    \n",
    "    best_feature =sort_entrop_change[0][0]\n",
    "    \n",
    "    return sort_entrop_change,best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def majorityCnt(classList):\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        classCount.setDefault(vote,0)\n",
    "        classCount[vote] +=1\n",
    "    sort = sorted(classCount.items(),key=lambda row:row[1],reverse=True)\n",
    "    return sort[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 'yes'], [1, 3, 'yes']]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_feature_x(data,axis,value):\n",
    "    splitdata=[]\n",
    "    for vect in data:\n",
    "        if vect[axis]==value:\n",
    "            temp = vect[:axis]\n",
    "            temp.extend(vect[axis+1:])\n",
    "            splitdata.append(temp)\n",
    "    return splitdata\n",
    "split_feature_x(data,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTree(dataset,label):\n",
    "    labels = label[:]\n",
    "    classList = [example[-1] for example in dataset]    # 因为后面对数据进行了切分，因此 dataset只是一个子集。\n",
    "    if classList.count(classList[0]) == len(classList): # 当一组数据的标签都完全一致是 则 停止分裂。\n",
    "        return classList[0]\n",
    "    if len(dataset[0])==1:                              # 没有特征可供划分时 则 停止划分， 么有往复的使用特征。\n",
    "        return majorityCnt(classList)                   # 这里使用的 投票法。\n",
    "    \n",
    "    _,bestFeat = chose_best_feature(dataset)\n",
    "    bestFeatLabel = labels[bestFeat]                    # labels 中存储的 是特制的 字符串名称 不是 取值，因此转换。\n",
    "    \n",
    "    myTree ={bestFeatLabel:{}}\n",
    "    del labels[bestFeat]  # 消除已经使用过的特征。\n",
    "    \n",
    "    featValues = [example[bestFeat] for example in dataset]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        myTree[bestFeatLabel][value]=createTree(split_feature_x(      # 根据特征的 每个类别 构建 多差树。\n",
    "        dataset,bestFeat,value),subLabels)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no surfacing': {0: 'no', 1: 'yes', 2: {'lk': {0: 'no', 2: 'yes'}}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'no surfacing'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,label = createDataSet()\n",
    "t = createTree(data,label)\n",
    "print(t)\n",
    "fir =[i for i in t.keys()][0]\n",
    "fir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no surfacing\n",
      "{0: 'no', 1: 'yes', 2: 'no'}\n",
      "0\n",
      "dict_keys([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "firstStr = [i for i in t.keys()][0]\n",
    "print(firstStr)\n",
    "secondDict = t[firstStr]\n",
    "print(secondDict)\n",
    "featIndex = labels.index(firstStr) # 在 Label 中 firstStr所在的位置 list.index(\"xx\")\n",
    "print(featIndex)\n",
    "print(secondDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(inputTree,featLabels,testVec):\n",
    "    firstStr = [i for i in inputTree.keys()][0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    \n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex]==key:\n",
    "            #if type(secondDict[key]).__name__=='dict':\n",
    "            if isinstance(secondDict[key],dict):\n",
    "                classLabel = classify(secondDict[key],featLabels,testVec)\n",
    "            else:\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = [i for i in mytree.keys()][0]\n",
    "sd = mytree[fs]\n",
    "sd\n",
    "fi = labels.index(fs)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,labels = createDataSet()\n",
    "feature_label = labels[:]\n",
    "mytree = createTree(data,labels)\n",
    "#classify(mytree,feature_label,[1,1])\n",
    "classify(mytree,labels,[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: 'yes', 2: {'lk': {0: 'no', 2: 'yes'}}}}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytree#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no surfacing\n",
      "{0: 'no', 1: 'yes', 2: {'lk': {0: 'no', 2: 'yes'}}}\n"
     ]
    }
   ],
   "source": [
    "for i in mytree.keys():\n",
    "    print(i)\n",
    "    print(mytree[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: 'yes', 2: {'lk': {0: 'no', 2: 'yes'}}}}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def storetree(putTree,filename):\n",
    "    import pickle\n",
    "    fw = open(filename,'wb')\n",
    "    pickle.dump(putTree,fw)\n",
    "    fw.close()\n",
    "    \n",
    "def loadtree(filename):\n",
    "    import pickle\n",
    "    fr = open(filename,'rb')\n",
    "    return pickle.load(fr)\n",
    "\n",
    "storetree(createTree,'./filetree.txt')\n",
    "\n",
    "m = loadtree('./filetree.txt')\n",
    "\n",
    "data,labels = createDataSet()\n",
    "m(data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(mytree.keys())[0]\n",
    "x\n",
    "se = mytree[x]\n",
    "se.keys()\n",
    "se[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree_leafs(mytree):\n",
    "    first_node = list(mytree.keys())[0]\n",
    "    num_leafs = 0\n",
    "    sencond_tree = mytree[first_node]\n",
    "    for key in sencond_tree.keys():\n",
    "        if isinstance(sencond_tree[key],dict):\n",
    "            num_leafs += tree_leafs(sencond_tree[key])\n",
    "        else:\n",
    "            num_leafs +=1 \n",
    "    return num_leafs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tree_deep(mytree):\n",
    "    first_node = list(mytree.keys())[0]\n",
    "    maxdeep = 0\n",
    "    second_tree = mytree[first_node]\n",
    "    for key in second_tree.keys():\n",
    "        if isinstance(second_tree[key],dict):\n",
    "            temp_deep = tree_deep(second_tree[key]) +1\n",
    "        else:\n",
    "            temp_deep = 1\n",
    "        maxdeep = max(maxdeep,temp_deep)\n",
    "    return maxdeep\n",
    "     \n",
    "tree_deep(mytree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GITHUB上的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luokui/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/luokui/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _h(i):\n",
    "    return np.log(i) + 0.5772156649 \n",
    "\n",
    "\n",
    "def _c(n):\n",
    "    if n > 2:\n",
    "        h = _h(n-1)\n",
    "        return 2*h - 2*(n - 1)/n\n",
    "    if n == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def _anomaly_score(score, n_samples):\n",
    "\n",
    "    score = -score/_c(n_samples)\n",
    "\n",
    "    return 2**score\n",
    "\n",
    "\n",
    "def _split_data(X):\n",
    "    ''' split the data in the left and right nodes ''' \n",
    "    n_samples, n_columns = X.shape\n",
    "    n_features = n_columns - 1\n",
    "    m = M = 0\n",
    "    while m == M:\n",
    "        feature_id = np.random.randint(low=0, high=n_features)\n",
    "        feature = X[:, feature_id]\n",
    "        m = feature.min()\n",
    "        M = feature.max()\n",
    "        #print(m, M, feature_id, X.shape)\n",
    "\n",
    "    split_value = np.random.uniform(m, M, 1)\n",
    "    left_X = X[feature <= split_value]\n",
    "    right_X = X[feature > split_value]\n",
    "    return left_X, right_X, feature_id, split_value\n",
    "\n",
    "\n",
    "def iTree(X, add_index=False, max_depth = np.inf):            \n",
    "    ''' construct an isolation tree and returns the number of step required\n",
    "    to isolate an element. A column of index is added to the input matrix X if  \n",
    "    add_index=True. This column is required in the algorithm. ''' \n",
    "\n",
    "    n_split = {} \n",
    "    def iterate(X, count = 0):\n",
    "\n",
    "        n_samples, n_columns = X.shape\n",
    "        n_features = n_columns - 1\n",
    "\n",
    "        if count > max_depth:\n",
    "            for index in X[:,-1]:\n",
    "                n_split[index] = count\n",
    "            return\n",
    "\n",
    "        if n_samples == 1:\n",
    "            index = X[0, n_columns-1]\n",
    "            n_split[index] = count\n",
    "            return \n",
    "        else:\n",
    "            lX, rX, feature_id, split_value = _split_data(X)\n",
    "            # Uncomment the print to visualize a draft of \n",
    "            # the construction of the tree\n",
    "            #print(lX[:,-1], rX[:,-1], feature_id, split_value, n_split)\n",
    "            n_samples_lX, _ = lX.shape\n",
    "            n_samples_rX, _ = rX.shape\n",
    "            if n_samples_lX > 0:\n",
    "                iterate(lX, count+1)\n",
    "            if n_samples_rX >0:\n",
    "                iterate(rX, count+1)\n",
    "\n",
    "    if add_index:\n",
    "        n_samples, _ = X.shape\n",
    "        X = np.c_[X, range(n_samples)]\n",
    "\n",
    "    iterate(X)\n",
    "    return n_split\n",
    "\n",
    "\n",
    "class iForest():\n",
    "    ''' Class to construct the isolation forest.\n",
    "\n",
    "    -n_estimators: is the number of trees in the forest,\n",
    "\n",
    "    -sample_size: is the bootstrap parameter used during the construction\n",
    "    of the forest,\n",
    "\n",
    "    -add_index: adds a column of index to the matrix X. This is required and \n",
    "    add_index can be set to False only if the last column of X contains \n",
    "    already indeces.\n",
    "\n",
    "    -max_depth: is the maximum depth of each tree\n",
    "    '''\n",
    "    def __init__(self, n_estimators=20, sample_size=None, add_index = True, \n",
    "                 max_depth = 100):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.sample_size = sample_size\n",
    "        self.add_index = add_index\n",
    "        self.max_depth = max_depth\n",
    "        return \n",
    "\n",
    "    def fit(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        if self.sample_size == None:\n",
    "            self.sample_size = int(n_samples/2)\n",
    "\n",
    "        if self.add_index:\n",
    "            X = np.c_[X, range(n_samples)]\n",
    "\n",
    "\n",
    "        trees = [iTree(X[np.random.choice(n_samples, self.sample_size,replace=False)]\n",
    "                       ,max_depth=self.max_depth) for i in range(self.n_estimators)]\n",
    "\n",
    "        self.path_length_ = {k:None for k in range(n_samples)}\n",
    "        for k in self.path_length_.keys():\n",
    "            self.path_length_[k] = np.array([tree[k] for tree in trees  if k in tree])\n",
    "        \n",
    "        self.path_length_ = np.array([self.path_length_[k].mean() for k in \n",
    "                                      self.path_length_.keys()])\n",
    "        self.anomaly_score_ = _anomaly_score(self.path_length_, self.sample_size)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
