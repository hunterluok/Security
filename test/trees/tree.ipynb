{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISOLATION Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = [[1,1,2],[3,2,4],[2,1,2],[3,1,2],[7,8,9],[2,1,2],[11,1,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data, col):\n",
    "    try:\n",
    "        feature_data = [line[col] for line in data]\n",
    "    except TypeError as e:\n",
    "        raise TypeError(\"the type is not fit de algo\")\n",
    "    feature_min_value = min(feature_data)\n",
    "    feature_max_value = max(feature_data)\n",
    "    random_value = feature_min_value + np.random.rand(1) * (feature_max_value - feature_min_value)\n",
    "    left_data = []\n",
    "    right_data = []\n",
    "    for line in data:\n",
    "        if line[col] >= random_value:\n",
    "            right_data.append(line)\n",
    "        else:\n",
    "            left_data.append(line)\n",
    "    return left_data, right_data, col, random_value\n",
    "\n",
    "\n",
    "def sample_data(data, ratio):\n",
    "    if isinstance(data, list):\n",
    "        m, n = len(data), len(data[0])\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        m, n = data.shape\n",
    "    \n",
    "    if 0 < ratio < 1:\n",
    "        sub_m = int(ratio * m)\n",
    "    elif isinstance(ratio, int):\n",
    "        sub_m = min(ratio, m)\n",
    "    \n",
    "    new_data = []\n",
    "    random_indx = np.random.permutation(m)[: sub_m]\n",
    "    for idx in random_indx:\n",
    "        new_data.append(data[idx])\n",
    "    return new_data, sub_m, n\n",
    "   \n",
    "# split_data(d)\n",
    "# random_data(d, ratio=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_deep(num):\n",
    "    return np.ceil(np.log2(num))\n",
    "\n",
    "def cost(num_items):\n",
    "    if num_items > 2:\n",
    "    # 二叉搜索树的平均路径长度。0.5772156649:欧拉常数\n",
    "        re =  2 * ((np.log2(num_items - 1) + 0.5772156649) - (num_items - 1) / num_items)\n",
    "        return re\n",
    "    elif num_items == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTree(data, num_col, max_deep, cur_deep = 0):\n",
    "    m, n = np.mat(data).shape\n",
    "    if cur_deep >= max_deep or m <= 1:  # 这个地方的 1 需要修稿的\n",
    "        return m\n",
    "\n",
    "    # 随机选择 一个特征进行数据划分\n",
    "    col = np.random.randint(num_col)\n",
    "    lSet, rSet, col, random_value = split_data(data, col)\n",
    "    retTree = {}\n",
    "    retTree['spInd'] = col\n",
    "    retTree['spVal'] = random_value\n",
    "    retTree['left'] = createTree(lSet, num_col, max_deep, cur_deep + 1)\n",
    "    retTree['right'] = createTree(rSet, num_col, max_deep, cur_deep + 1)\n",
    "    return retTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-495-5c4d52056e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misolation_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mpredict_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-495-5c4d52056e70>\u001b[0m in \u001b[0;36mpredict_score\u001b[0;34m(x, ITrees, data_num)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mITrees\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-487-3a6b74f54af8>\u001b[0m in \u001b[0;36mget_length\u001b[0;34m(tree, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msplit_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spVal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msplit_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spInd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msplit_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "def isolation_forest(data, ratio, num_trees=10):\n",
    "    Trees = []\n",
    "    sub_ms = []\n",
    "    for i in range(10):\n",
    "        random_data, sub_m, num_feature = sample_data(data, ratio)\n",
    "        max_deep = get_max_deep(sub_m)\n",
    "        ITree = createTree(random_data, num_feature, max_deep)\n",
    "        Trees.append(ITree)\n",
    "        sub_ms.append(sub_m)\n",
    "    return Trees, sub_ms\n",
    "    \n",
    "#trees,sub_ms = isolation_forest(d,5)\n",
    "#trees\n",
    "\n",
    "def predict_score(x, ITrees, data_num):\n",
    "    predictions = []\n",
    "    for itree in ITrees:\n",
    "        predict = get_length(itree, x)\n",
    "        predictions.append(predict)\n",
    "    return np.power(2, -np.sum(predictions) /len(predictions) / cost(data_num))  \n",
    "\n",
    "trees = isolation_forest(np.array(d), ratio=0.9)\n",
    "predict_score([100,200,300],trees,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-487-3a6b74f54af8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmdeep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mget_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmytree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-487-3a6b74f54af8>\u001b[0m in \u001b[0;36mget_length\u001b[0;34m(tree, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msplit_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spVal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msplit_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spInd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msplit_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def get_length(tree, x): \n",
    "    split_value = tree['spVal']\n",
    "    split_ind = tree['spInd']\n",
    "    \n",
    "    if x[split_ind] > split_value:\n",
    "        if isinstance(tree['right'], dict):\n",
    "            mdeep = 1 + get_length(tree['right'], x)\n",
    "        else:\n",
    "            mdeep = cost(tree['right']) # 注意这里的平滑系数。\n",
    "    else: \n",
    "        if isinstance(tree['left'],dict):\n",
    "            mdeep = 1 + get_length(tree['left'], x)\n",
    "        else:\n",
    "            mdeep = cost(tree['left']) # 当 2为 当样本数量很少时。\n",
    "    return mdeep\n",
    "\n",
    "get_length(mytree,x = [0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_score(x, ITrees, data_num):\n",
    "    predictions = []\n",
    "    for itree in ITrees:\n",
    "        predict = get_length(itree, x)\n",
    "        predictions.append(predict)\n",
    "    return np.power(2, -np.sum(predictions) /len(predictions) / cost(data_num))  \n",
    "\n",
    "predict_score([100,200,300],trees,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算树的 deep 及 叶子树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tree_leafs(mytree):\n",
    "    num_feature = 0\n",
    "    for key in mytree.keys():\n",
    "        if isinstance(mytree[key], dict):\n",
    "            num_feature += tree_leafs(mytree[key])\n",
    "        else:\n",
    "            num_feature += 1 # mytree[key]\n",
    "    return num_feature\n",
    "tree_leafs(mytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tree_deep(mytree):\n",
    "    max_deep = 0\n",
    "    for key in mytree.keys():\n",
    "        if isinstance(mytree[key], dict):\n",
    "            temp_deep = tree_deep(mytree[key]) + 1\n",
    "        else:\n",
    "            temp_deep = 1   \n",
    "        max_deep = max(max_deep, temp_deep)\n",
    "    return max_deep\n",
    "tree_deep(mytree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 多叉树 ，且每个特征只使用一次，只适合 类型较少的 分类型数据。\n",
    "\n",
    "import numpy as np\n",
    "def createDataSet():\n",
    "    dataSet = [[1, 1,2, 'yes'],\n",
    "               [1, 1,3,'yes'],\n",
    "               [2, 0,1,'no'],\n",
    "               [0, 1,3,'no'],\n",
    "               [0, 1,3,'no'],\n",
    "               [2, 2,1,'yes']   \n",
    "              ]\n",
    "              #[1,1,'maybe']]\n",
    "    labels = ['no surfacing','lk','flippers']\n",
    "    return dataSet, labels\n",
    "\n",
    "data,label = createDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal(data)->\"input:最后一列带标签的数据，output:entropy\": \n",
    "    cout_dic ={}\n",
    "    if isinstance(data,list):\n",
    "        m = len(data)\n",
    "    elif isinstance(data,np.ndarray):  # 这里需要注意哦。 numpy.ndarray\n",
    "        m = data.shape[0]\n",
    "    else:\n",
    "        raise ValueError(\"The type of the data must be LIST or ARRAY\")\n",
    "    for i in range(m):\n",
    "        temp = data[i][-1]\n",
    "        cout_dic.setdefault(temp,0)\n",
    "        cout_dic[temp] +=1\n",
    "    cout_dic = {k:-(v/m)*(np.log2(v/m)) for k,v in cout_dic.items()}\n",
    "    entrop = sum(cout_dic.values())\n",
    "    return entrop\n",
    "\n",
    "cal(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, {'no': 0.25, 'yes': 0.25})"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini(data):\n",
    "    cout_dic ={}\n",
    "    m = len(data)\n",
    "    for i in range(m):\n",
    "        temp = data[i][-1]\n",
    "        cout_dic.setdefault(temp,0)\n",
    "        cout_dic[temp] +=1\n",
    "    cout_dic = {k:(v/m)**2 for k,v in cout_dic.items()}\n",
    "    gini = 1- sum(cout_dic.values())\n",
    "    return gini,cout_dic\n",
    "gini(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_feature(data,k=0):\n",
    "    m = len(data)\n",
    "    #n = len(data[0])\n",
    "    data = np.array(data)\n",
    "    t = np.unique(data[:,k])\n",
    "    splitdata={}\n",
    "    for i in t:\n",
    "        for j in range(m):\n",
    "            if data[j,k]==i:\n",
    "                splitdata.setdefault(i,[])\n",
    "                splitdata[i].append(data[j])\n",
    "    return splitdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnew_entrop=0.\\nfor key,value in xx.items():\\n    length =len(value)\\n    new_entrop +=length/5 *cal(value)\\n    #new_entrop +=cal(value)\\n    print(new_entrop)\\n'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "new_entrop=0.\n",
    "for key,value in xx.items():\n",
    "    length =len(value)\n",
    "    new_entrop +=length/5 *cal(value)\n",
    "    #new_entrop +=cal(value)\n",
    "    print(new_entrop)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "（1）计算未 划分前的entropy\n",
    "（2）根据每一个 特征的 值 进行划分，计算 entropy的改变量，选择 改变量最大的 特征和 特征值。\n",
    "（3）然后 递归的 对数据进行划分，只到满足特定的条件\n",
    "（4）计算 树的 最大深度 和枝叶数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 选择最优的分裂的枝叶。\n",
    "def chose_best_feature(data):\n",
    "    if isinstance(data, list):\n",
    "        old_entrop = cal(data)\n",
    "        n = len(data[0]) - 1\n",
    "        entrop_change = {}\n",
    "        len_data = len(data)\n",
    "    else:\n",
    "        raise TypeError(\"The type of the data must be List\")\n",
    "    \n",
    "    for i in range(n):\n",
    "        temp = split_feature(data, k=i)\n",
    "        new_entrop = 0.\n",
    "        for key, value in temp.items():\n",
    "            length = len(value)\n",
    "            new_entrop += length / len_data * cal(value) #这里注意用法。 数据集划分之后 标签的 信息熵。\n",
    "        entrop_change.setdefault(i, 0)\n",
    "        entrop_change[i] = old_entrop - new_entrop\n",
    "    sort_entrop_change = sorted(entrop_change.items(), key=lambda row: row[1], reverse=True)\n",
    "    best_feature =sort_entrop_change[0][0]\n",
    "    \n",
    "    return sort_entrop_change, best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def majorityCnt(classList):\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        classCount.setDefault(vote,0)\n",
    "        classCount[vote] +=1\n",
    "    sort = sorted(classCount.items(),key=lambda row:row[1],reverse=True)\n",
    "    return sort[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 'yes'], [1, 3, 'yes']]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_feature_x(data,axis,value):\n",
    "    splitdata=[]\n",
    "    for vect in data:\n",
    "        if vect[axis]==value:\n",
    "            temp = vect[:axis]\n",
    "            temp.extend(vect[axis+1:])\n",
    "            splitdata.append(temp)\n",
    "    return splitdata\n",
    "split_feature_x(data,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTree(dataset,label):\n",
    "    labels = label[:]\n",
    "    classList = [example[-1] for example in dataset]    # 因为后面对数据进行了切分，因此 dataset只是一个子集。\n",
    "    if classList.count(classList[0]) == len(classList): # 当一组数据的标签都完全一致是 则 停止分裂。\n",
    "        return classList[0]\n",
    "    if len(dataset[0])==1:                              # 没有特征可供划分时 则 停止划分， 么有往复的使用特征。\n",
    "        return majorityCnt(classList)                   # 这里使用的 投票法。\n",
    "    \n",
    "    _, bestFeat = chose_best_feature(dataset)\n",
    "    bestFeatLabel = labels[bestFeat]                    # labels 中存储的 是特制的 字符串名称 不是 取值，因此转换。\n",
    "    \n",
    "    myTree ={bestFeatLabel:{}}\n",
    "    del labels[bestFeat]  # 消除已经使用过的特征。\n",
    "    \n",
    "    featValues = [example[bestFeat] for example in dataset]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        myTree[bestFeatLabel][value]=createTree(split_feature_x(      # 根据特征的 每个类别 构建 多差树。\n",
    "        dataset, bestFeat, value), subLabels)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no surfacing': {0: 'no', 1: 'yes', 2: {'lk': {0: 'no', 2: 'yes'}}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'no surfacing'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,label = createDataSet()\n",
    "t = createTree(data,label)\n",
    "print(t)\n",
    "fir =[i for i in t.keys()][0]\n",
    "fir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no surfacing\n",
      "{0: 'no', 1: 'yes', 2: 'no'}\n",
      "0\n",
      "dict_keys([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "firstStr = [i for i in t.keys()][0]\n",
    "print(firstStr)\n",
    "secondDict = t[firstStr]\n",
    "print(secondDict)\n",
    "featIndex = labels.index(firstStr) # 在 Label 中 firstStr所在的位置 list.index(\"xx\")\n",
    "print(featIndex)\n",
    "print(secondDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(inputTree,featLabels,testVec):\n",
    "    firstStr = [i for i in inputTree.keys()][0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    \n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex]==key:\n",
    "            #if type(secondDict[key]).__name__=='dict':\n",
    "            if isinstance(secondDict[key],dict):\n",
    "                classLabel = classify(secondDict[key],featLabels,testVec)\n",
    "            else:\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = [i for i in mytree.keys()][0]\n",
    "sd = mytree[fs]\n",
    "sd\n",
    "fi = labels.index(fs)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,labels = createDataSet()\n",
    "feature_label = labels[:]\n",
    "mytree = createTree(data,labels)\n",
    "#classify(mytree,feature_label,[1,1])\n",
    "classify(mytree,labels,[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: 'yes', 2: {'lk': {0: 'no', 2: 'yes'}}}}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytree#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no surfacing\n",
      "{0: 'no', 1: 'yes', 2: {'lk': {0: 'no', 2: 'yes'}}}\n"
     ]
    }
   ],
   "source": [
    "for i in mytree.keys():\n",
    "    print(i)\n",
    "    print(mytree[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: 'yes', 2: {'lk': {0: 'no', 2: 'yes'}}}}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def storetree(putTree,filename):\n",
    "    import pickle\n",
    "    fw = open(filename,'wb')\n",
    "    pickle.dump(putTree,fw)\n",
    "    fw.close()\n",
    "    \n",
    "def loadtree(filename):\n",
    "    import pickle\n",
    "    fr = open(filename,'rb')\n",
    "    return pickle.load(fr)\n",
    "\n",
    "storetree(createTree,'./filetree.txt')\n",
    "\n",
    "m = loadtree('./filetree.txt')\n",
    "\n",
    "data,labels = createDataSet()\n",
    "m(data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(mytree.keys())[0]\n",
    "x\n",
    "se = mytree[x]\n",
    "se.keys()\n",
    "se[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree_leafs(mytree):\n",
    "    first_node = list(mytree.keys())[0]\n",
    "    num_leafs = 0\n",
    "    sencond_tree = mytree[first_node]\n",
    "    for key in sencond_tree.keys():\n",
    "        if isinstance(sencond_tree[key],dict):\n",
    "            num_leafs += tree_leafs(sencond_tree[key])\n",
    "        else:\n",
    "            num_leafs +=1 \n",
    "    return num_leafs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tree_deep(mytree):\n",
    "    first_node = list(mytree.keys())[0]\n",
    "    maxdeep = 0\n",
    "    second_tree = mytree[first_node]\n",
    "    for key in second_tree.keys():\n",
    "        if isinstance(second_tree[key],dict):\n",
    "            temp_deep = tree_deep(second_tree[key]) +1\n",
    "        else:\n",
    "            temp_deep = 1\n",
    "        maxdeep = max(maxdeep,temp_deep)\n",
    "    return maxdeep\n",
    "     \n",
    "tree_deep(mytree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GITHUB上的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luokui/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/luokui/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _h(i):\n",
    "    return np.log(i) + 0.5772156649 \n",
    "\n",
    "\n",
    "def _c(n):\n",
    "    if n > 2:\n",
    "        h = _h(n-1)\n",
    "        return 2*h - 2*(n - 1)/n\n",
    "    if n == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def _anomaly_score(score, n_samples):\n",
    "\n",
    "    score = -score/_c(n_samples)\n",
    "\n",
    "    return 2**score\n",
    "\n",
    "\n",
    "def _split_data(X):\n",
    "    ''' split the data in the left and right nodes ''' \n",
    "    n_samples, n_columns = X.shape\n",
    "    n_features = n_columns - 1\n",
    "    m = M = 0\n",
    "    while m == M:\n",
    "        feature_id = np.random.randint(low=0, high=n_features)\n",
    "        feature = X[:, feature_id]\n",
    "        m = feature.min()\n",
    "        M = feature.max()\n",
    "        #print(m, M, feature_id, X.shape)\n",
    "\n",
    "    split_value = np.random.uniform(m, M, 1)\n",
    "    left_X = X[feature <= split_value]\n",
    "    right_X = X[feature > split_value]\n",
    "    return left_X, right_X, feature_id, split_value\n",
    "\n",
    "\n",
    "def iTree(X, add_index=False, max_depth = np.inf):            \n",
    "    ''' construct an isolation tree and returns the number of step required\n",
    "    to isolate an element. A column of index is added to the input matrix X if  \n",
    "    add_index=True. This column is required in the algorithm. ''' \n",
    "\n",
    "    n_split = {} \n",
    "    def iterate(X, count = 0):\n",
    "\n",
    "        n_samples, n_columns = X.shape\n",
    "        n_features = n_columns - 1\n",
    "\n",
    "        if count > max_depth:\n",
    "            for index in X[:,-1]:\n",
    "                n_split[index] = count\n",
    "            return\n",
    "\n",
    "        if n_samples == 1:\n",
    "            index = X[0, n_columns-1]\n",
    "            n_split[index] = count\n",
    "            return \n",
    "        else:\n",
    "            lX, rX, feature_id, split_value = _split_data(X)\n",
    "            # Uncomment the print to visualize a draft of \n",
    "            # the construction of the tree\n",
    "            #print(lX[:,-1], rX[:,-1], feature_id, split_value, n_split)\n",
    "            n_samples_lX, _ = lX.shape\n",
    "            n_samples_rX, _ = rX.shape\n",
    "            if n_samples_lX > 0:\n",
    "                iterate(lX, count+1)\n",
    "            if n_samples_rX >0:\n",
    "                iterate(rX, count+1)\n",
    "\n",
    "    if add_index:\n",
    "        n_samples, _ = X.shape\n",
    "        X = np.c_[X, range(n_samples)]\n",
    "\n",
    "    iterate(X)\n",
    "    return n_split\n",
    "\n",
    "\n",
    "class iForest():\n",
    "    ''' Class to construct the isolation forest.\n",
    "\n",
    "    -n_estimators: is the number of trees in the forest,\n",
    "\n",
    "    -sample_size: is the bootstrap parameter used during the construction\n",
    "    of the forest,\n",
    "\n",
    "    -add_index: adds a column of index to the matrix X. This is required and \n",
    "    add_index can be set to False only if the last column of X contains \n",
    "    already indeces.\n",
    "\n",
    "    -max_depth: is the maximum depth of each tree\n",
    "    '''\n",
    "    def __init__(self, n_estimators=20, sample_size=None, add_index = True, \n",
    "                 max_depth = 100):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.sample_size = sample_size\n",
    "        self.add_index = add_index\n",
    "        self.max_depth = max_depth\n",
    "        return \n",
    "\n",
    "    def fit(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        if self.sample_size == None:\n",
    "            self.sample_size = int(n_samples/2)\n",
    "\n",
    "        if self.add_index:\n",
    "            X = np.c_[X, range(n_samples)]\n",
    "\n",
    "\n",
    "        trees = [iTree(X[np.random.choice(n_samples, self.sample_size,replace=False)]\n",
    "                       ,max_depth=self.max_depth) for i in range(self.n_estimators)]\n",
    "\n",
    "        self.path_length_ = {k:None for k in range(n_samples)}\n",
    "        for k in self.path_length_.keys():\n",
    "            self.path_length_[k] = np.array([tree[k] for tree in trees  if k in tree])\n",
    "        \n",
    "        self.path_length_ = np.array([self.path_length_[k].mean() for k in \n",
    "                                      self.path_length_.keys()])\n",
    "        self.anomaly_score_ = _anomaly_score(self.path_length_, self.sample_size)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## cart tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mytree:\n",
    "    def __init__(self, feature=-1, value=None, left_tree=None, right_tree=None, label_class=None):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.left_tree = left_tree\n",
    "        self.right_tree = right_tree\n",
    "        self.label_class = label_class\n",
    "\n",
    "class mycarttree:       \n",
    "    def __init__(self, min_leafs):\n",
    "        self.min_leafs = min_leafs\n",
    "    \n",
    "    def calculate_gini(self, label):\n",
    "        temp_dicts = {}\n",
    "        for temp_label in label:\n",
    "            temp_label = temp_label[0]\n",
    "            temp_dicts.setdefault(temp_label, 0)\n",
    "            temp_dicts[temp_label] += 1\n",
    "            \n",
    "        temp_count = np.array([i for i in temp_dicts.values()])\n",
    "        sum_values = np.sum(temp_count)\n",
    "        gini_value = 1 - np.sum(np.power(temp_count/sum_values, 2))\n",
    "        return gini_value\n",
    "    \n",
    "    def split_data(self, data, feature, value, label):\n",
    "        if not label.shape:\n",
    "            raise TypeError(\"label muste be two dim\")\n",
    "        m, n = data.shape\n",
    "        condition_left = data[:, feature] <= value\n",
    "        condition_right = data[:, feature] > value\n",
    "        \n",
    "        left_data = data[condition_left]\n",
    "        right_data = data[condition_right]\n",
    "        left_label = label[condition_left]\n",
    "        right_label = label[condition_right]\n",
    "\n",
    "        split_gini = (left_label.shape[0]/m) * self.calculate_gini(left_label) + (right_label.shape[0]/m) * self.calculate_gini(right_label)\n",
    "        return left_data, left_label, right_data, right_label, split_gini\n",
    "    \n",
    "    def find_best_split(self, data, label):\n",
    "        m, n = data.shape\n",
    "        \n",
    "        best_feature = None\n",
    "        best_feature_value = None\n",
    "        best_left_data = None\n",
    "        best_right_data = None\n",
    "        best_left_label = None\n",
    "        best_right_label = None\n",
    "        \n",
    "        max_ginigain = 0\n",
    "        init_gini = self.calculate_gini(label)\n",
    "        \n",
    "        for feature_index in range(n):\n",
    "            feature_values = set(data[:, feature_index])\n",
    "            for feature_value in feature_values:\n",
    "                left_data, left_label, right_data, right_label, split_gini = self.split_data(data, feature_index, feature_value, label)\n",
    "                temp_ginigain = init_gini - split_gini\n",
    "                if temp_ginigain >  max_ginigain and len(left_data)>0 and len(right_data)>0:\n",
    "                    max_ginigain = temp_ginigain\n",
    "                    best_feature = feature_index\n",
    "                    best_feature_value = feature_value\n",
    "                    best_left_data = left_data\n",
    "                    best_right_data = right_data\n",
    "                    best_left_label = left_label\n",
    "                    best_right_label = right_label\n",
    "        return best_feature, best_feature_value, best_left_data, best_right_data, best_left_label, best_right_label\n",
    "       \n",
    "    def get_result(self, label):\n",
    "        return Counter([i[0] for i in label]).most_common()[0][0]\n",
    "        \n",
    "    def fit(self, data, label):\n",
    "        if len(data) == 0:\n",
    "            return mytree()\n",
    "        elif len(np.unique(label))==1:\n",
    "            return mytree(label_class = self.get_result(label))\n",
    "        \n",
    "        best_feature, best_feature_value, best_left_data, best_right_data, best_left_label, best_right_label = self.find_best_split(data, label)\n",
    "        \n",
    "        if best_feature:\n",
    "            right = self.fit(best_right_data, best_right_label)\n",
    "            left = self.fit(best_left_data, best_left_label)\n",
    "            \n",
    "            mytrees.feature = best_feature\n",
    "            mytrees.value = best_feature_value\n",
    "            mytrees.left_tree = left\n",
    "            mytrees.right_tree = right\n",
    "            return mytree(feature=best_feature, value=best_feature_value, left_tree=left, right_tree=right)\n",
    "        else:\n",
    "            return mytree(label_class = self.get_result(label))\n",
    "            \n",
    "    #@staticmethod\n",
    "    @classmethod\n",
    "    def predict_line(cls, model, line, high=0):\n",
    "        #m, n = line.shape\n",
    "        #if m != 1:\n",
    "         #   raise TypeError(\"xx\")\n",
    "        # 这里需要注意-> 这里只会返回一个值，而不是多个值。\n",
    "        if model.label_class is not None:\n",
    "            # print(high)\n",
    "            return model.label_class\n",
    "        split_feature = model.feature\n",
    "        split_value = model.value\n",
    "        \n",
    "        temp_value = line[split_feature]\n",
    "        if temp_value <= split_value:\n",
    "            return cls.predict_line(model.left_tree, line, high=high+1)\n",
    "        else:\n",
    "            return cls.predict_line(model.right_tree, line, high=high+1)\n",
    "       \n",
    "    @classmethod\n",
    "    def predict(cls, model, data):\n",
    "        myre = []\n",
    "        for line in data:\n",
    "            te = cls.predict_line(model, line)\n",
    "            myre.append(te)\n",
    "        myre = np.array(myre).reshape(len(data), 1)\n",
    "        return myre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()['data']\n",
    "mylabel = load_iris()['target']\n",
    "mylabel = np.array([[i] for i in mylabel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "mymodel = mycarttree(4)\n",
    "result = mymodel.fit(data, mylabel)\n",
    "preds = mymodel.predict(result, data)\n",
    "acc = np.sum(preds == mylabel) / 150\n",
    "acc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 0, 9, 6, 1, 3, 5, 7, 4, 2])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 7, 6, 5, 0, 9, 8, 4, 3, 2])"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.arange(10)\n",
    "random.shuffle(index)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 0, 1, 4, 3, 6, 8, 9, 2])"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_model(data, label, ratio=0.9):\n",
    "    m, n = data.shape\n",
    "    index = np.arange(m)\n",
    "    random.shuffle(index)\n",
    "    #index = np.random.permutation(np.arange(m))\n",
    "    # feature_index = np.random.permutation(np.arange(n))\n",
    "    nums = index[:int(ratio * m)]\n",
    "    n_data = data[nums]\n",
    "    n_label = label[nums]\n",
    "    return n_data, n_label\n",
    "\n",
    "\n",
    "def myjob(q, r=0.9, data=data, mylabel=mylabel):\n",
    "    #r = np.random.uniform(0.8, 1)\n",
    "    # 这种搞随机数是不可行的，\n",
    "    my_data, my_label = single_model(data, mylabel, ratio=r)\n",
    "    mymodel = mycarttree(2)\n",
    "    result = mymodel.fit(my_data, my_label)\n",
    "    \n",
    "    m, _ = data.shape\n",
    "    preds = mymodel.predict(result, data)\n",
    "    acc = np.round(np.sum(preds == mylabel) / m, 2)\n",
    "    print(\"this model's acc is {}\".format(acc))\n",
    "    q.put(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this model's acc is 0.99\n",
      "this model's acc is 0.97\n",
      "this model's acc is 0.98\n"
     ]
    }
   ],
   "source": [
    "q = Queue()\n",
    "tmp1 = Process(target=myjob, args=(q, 0.9), name=\"job1\")\n",
    "tmp2 = Process(target=myjob, args=(q, 0.9), name=\"job2\")\n",
    "tmp3 = Process(target=myjob, args=(q, 0.9), name=\"job3\")\n",
    "tmp1.start()\n",
    "tmp2.start()\n",
    "tmp3.start()\n",
    "tmp1.join()\n",
    "tmp2.join()\n",
    "tmp3.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this model's acc is 0.96\n",
      "this model's acc is 0.96\n",
      "this model's acc is 0.99\n",
      "this model's acc is 0.99\n",
      "this model's acc is 0.99\n",
      "last_label acc is 0.99\n"
     ]
    }
   ],
   "source": [
    "q = Queue()\n",
    "myqueus = []\n",
    "\n",
    "rlist=[0.7, 0.8, 0.85, 0.9, 0.95]\n",
    "for i, r in zip(range(5), rlist):\n",
    "    temp_job = Process(target=myjob, args=(q, r), name=\"jon_{}\".format(i))\n",
    "    myqueus.append(temp_job)\n",
    "    \n",
    "for jons in myqueus:\n",
    "    jons.start()\n",
    "    \n",
    "for jons in myqueus:\n",
    "    jons.join()\n",
    "    \n",
    "nps = -1 * np.ones((150, 1))\n",
    "#for myres in q.get():\n",
    "for _ in range(5):\n",
    "    nps = np.concatenate([nps,q.get()], axis=1)\n",
    "    #nps.append(q.get())\n",
    "\n",
    "    \n",
    "last_label = get_label(nps)\n",
    "acc = np.round(np.sum(last_label == mylabel) / 150, 2)\n",
    "print(\"last_label acc is {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label(nps_data=nps):\n",
    "    last_label = []\n",
    "    for line in nps_data:\n",
    "        temp_label = Counter(line).most_common()[0][0]\n",
    "        last_label.append([temp_label])\n",
    "    return np.array(last_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二叉搜索树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _node:\n",
    "    def __init__(self, value=None, left=None, right=None):\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "class mysearch:            \n",
    "    def __init__(self):\n",
    "        self.mynode = _node()\n",
    "    \n",
    "    def insertdata(self, data):\n",
    "        # 插入数据\n",
    "        new_node = _node(value=data)\n",
    "        if self.mynode.value is None:\n",
    "            self.mynode = new_node\n",
    "            return \n",
    "            \n",
    "        temp = self.mynode\n",
    "        if data > temp.value:\n",
    "            if temp.right is None:\n",
    "                temp.right = new_node\n",
    "        else:\n",
    "            if temp.left is None:\n",
    "                temp.left = new_node\n",
    "                \n",
    "    @classmethod\n",
    "    def print_nodevalue(cls, model,i=0):\n",
    "        \"\"\"\n",
    "        如何递归的去打印子叶节点的，标号。#这里是中序遍历。\n",
    "        \"\"\"\n",
    "        \n",
    "        #if model.left is not None:\n",
    "            #cls.print_nodevalue(model.left, i=i+1)\n",
    "        if model.value is not None:\n",
    "            # print(model.value)\n",
    "            print(\"level {}, model value is {}\".format(i, model.value))\n",
    "        if model.left is not None:\n",
    "            cls.print_nodevalue(model.left, i=i+1)\n",
    "        if model.right is not None:\n",
    "            cls.print_nodevalue(model.right, i=i+1)\n",
    "            \n",
    "    @classmethod\n",
    "    def get_treedeep(cls, tree):\n",
    "        \"\"\"\n",
    "        计算树的最大深度\n",
    "        \"\"\"\n",
    "        max_deep = 0\n",
    "        if tree.left is not None:\n",
    "            temp_deep = 1 + cls.get_treedeep(tree.left)\n",
    "            if temp_deep > max_deep:\n",
    "                max_deep = temp_deep\n",
    "        if tree.right is not None:\n",
    "            temp_deep = 1 + cls.get_treedeep((tree.right))\n",
    "            if temp_deep > max_deep:\n",
    "                max_deep = temp_deep\n",
    "        return max_deep\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def find_value(cls, model, data):\n",
    "        # 没法用 RETURN \n",
    "        if model.value == data:\n",
    "            print(\"find\")\n",
    "        if model.left is not None:\n",
    "            cls.find_value(model.left, data)\n",
    "        if model.right is not None:\n",
    "            cls.find_value(model.right, data)\n",
    "\n",
    "    @property\n",
    "    def allnode(self):\n",
    "        return self.mynode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "class newnode(mysearch):\n",
    "    def __init__(self):\n",
    "        super(newnode, self).__init__()\n",
    "        self.mynode = _node()\n",
    "    \n",
    "    def insertdata(self, data):\n",
    "        new_node = _node(value=data)\n",
    "        if self.mynode.value is None:\n",
    "            self.mynode = new_node\n",
    "            return \n",
    "        \n",
    "        # 实现多个输入的方法。temp, cur类似于指针的东西 在作用。\n",
    "        temp = self.mynode\n",
    "        while temp is not None:\n",
    "            cur = temp\n",
    "            if data > temp.value:\n",
    "                temp = temp.right\n",
    "            else:\n",
    "                temp = temp.left\n",
    "        \n",
    "        # 给 指针插入新的数据点，就可以了。\n",
    "        if data > cur.value:\n",
    "            cur.right = new_node\n",
    "        else:\n",
    "            cur.left = new_node\n",
    "        print(\"ok insertone\")\n",
    "        \n",
    "    @classmethod\n",
    "    def print_nodevalue(cls, model,i=0):\n",
    "        \"\"\"\n",
    "        如何递归的去打印子叶节点的，标号。#这里是中序遍历。\n",
    "        \"\"\"\n",
    "        #if model.left is not None:\n",
    "            #cls.print_nodevalue(model.left, i=i+1)\n",
    "        if model.left is not None:\n",
    "            cls.print_nodevalue(model.left, i=i+1)\n",
    "        if model.value is not None:\n",
    "            # print(model.value)\n",
    "            print(\"level {}, model value is {}\".format(i, model.value))\n",
    "        if model.right is not None:\n",
    "            cls.print_nodevalue(model.right, i=i+1)\n",
    "    \n",
    "    @classmethod        \n",
    "    def omit_node(cls, model, data):\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my = s.allnode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok insertone\n",
      "ok insertone\n",
      "ok insertone\n",
      "ok insertone\n",
      "ok insertone\n",
      "ok insertone\n",
      "ok insertone\n",
      "ok insertone\n",
      "level 2, model value is 0.9\n",
      "level 1, model value is 1\n",
      "level 4, model value is 2\n",
      "level 3, model value is 3\n",
      "level 2, model value is 4\n",
      "level 0, model value is 9\n",
      "level 2, model value is 9.5\n",
      "level 1, model value is 10\n",
      "level 2, model value is 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = newnode()\n",
    "s.insertdata(9)\n",
    "s.insertdata(1)\n",
    "s.insertdata(4)\n",
    "s.insertdata(0.9)\n",
    "s.insertdata(10)\n",
    "s.insertdata(25)\n",
    "s.insertdata(9.5)\n",
    "s.insertdata(3)\n",
    "s.insertdata(2)\n",
    "s.print_nodevalue(s.allnode)\n",
    "s.get_treedeep(s.allnode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find\n"
     ]
    }
   ],
   "source": [
    "s.find_value(s.allnode, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "d = np.array([6, 3, 1, 4, 2, 5, 3, 7, 2])\n",
    "d\n",
    "d = np.array([2,3, 0, 1,0, 2, 5, 3, 3])\n",
    "d = np.array([0, 1, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "dicts = {}\n",
    "for i in range(len(d)):\n",
    "    #if i != d[i]:\n",
    "    while i != d[i]:\n",
    "        index = d[i]\n",
    "        d[i], d[index] = d[index], index\n",
    "        if d[i] == d[index]:\n",
    "            print(d[i])\n",
    "            dicts.setdefault(d[i], 0)\n",
    "            dicts[d[i]] += 1\n",
    "            break \n",
    "\n",
    "print(dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
